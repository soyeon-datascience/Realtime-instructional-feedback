{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8498dd77-e174-4c10-a2b1-fd4e6788d489",
   "metadata": {},
   "source": [
    "# 50-audio-training\n",
    "> Starting to use audio for training\n",
    "\n",
    "In this notebook, we use a few custom labeled transcripts (see [Issue #49](https://github.com/vanderbilt-data-science/wise/issues/49) for details) to extract subsegments of the audio files which correspond to the labels.  For this reason, we can now use this to directly train the head of a Wav2Vec2 Sequence Classification model.  We'll look into subsetting the data reliably and training the models below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf135c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_no_test\n",
    "#default_exp audio_modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b632d1-017f-4388-bbe9-981f6cdf1560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#modeling imports\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForSequenceClassification, pipeline, TrainingArguments, Trainer\n",
    "from datasets import load_metric\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import librosa\n",
    "\n",
    "#ds imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#python imports\n",
    "import os.path\n",
    "import glob\n",
    "import re\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa67484",
   "metadata": {},
   "source": [
    "# Organize data\n",
    "First, we need to have the data in some sort of reasonable form.  We'll make some functions here that can help us out with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813cdc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file constants\n",
    "base_prefix = '/data/p_dsi/wise/data/'\n",
    "sample_csv_dir = base_prefix + 'test_files/'\n",
    "audio_dir = base_prefix + 'resampled_audio_16khz/'\n",
    "test_audio_id = '055-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1a2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c0549b",
   "metadata": {},
   "source": [
    "## Read in sampled csv\n",
    "Currently, we're just going to take a look at a few files that have been hand-labeled with timestamps provided.  Let's check out just one to start out with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef76947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_csvs = glob.glob(sample_csv_dir + '*.csv')\n",
    "len(available_csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a0561f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using file: /data/p_dsi/wise/data/test_files/055-1.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>transcript_filepath</th>\n",
       "      <th>wave_filename</th>\n",
       "      <th>speech</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>end_timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>transcriber_id</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>055-1</td>\n",
       "      <td>~/Box Sync/DSI Documents/cleaned_data/cleaned_...</td>\n",
       "      <td>~/Box Sync/DSI Documents/Audio Files &amp; Tanscri...</td>\n",
       "      <td>(okay) we are gonna go on and get started guys.</td>\n",
       "      <td>00:01.000</td>\n",
       "      <td>00:03.380</td>\n",
       "      <td>NEU</td>\n",
       "      <td>198</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>055-1</td>\n",
       "      <td>~/Box Sync/DSI Documents/cleaned_data/cleaned_...</td>\n",
       "      <td>~/Box Sync/DSI Documents/Audio Files &amp; Tanscri...</td>\n",
       "      <td>we are gonna do a little bit of reviewing with...</td>\n",
       "      <td>00:03.750</td>\n",
       "      <td>00:06.763</td>\n",
       "      <td>NEU</td>\n",
       "      <td>198</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>055-1</td>\n",
       "      <td>~/Box Sync/DSI Documents/cleaned_data/cleaned_...</td>\n",
       "      <td>~/Box Sync/DSI Documents/Audio Files &amp; Tanscri...</td>\n",
       "      <td>(now) keep in mind that we are playing the goo...</td>\n",
       "      <td>00:07.150</td>\n",
       "      <td>00:12.769</td>\n",
       "      <td>NEU</td>\n",
       "      <td>198</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>055-1</td>\n",
       "      <td>~/Box Sync/DSI Documents/cleaned_data/cleaned_...</td>\n",
       "      <td>~/Box Sync/DSI Documents/Audio Files &amp; Tanscri...</td>\n",
       "      <td>everyone look up here please.</td>\n",
       "      <td>00:14.012</td>\n",
       "      <td>00:16.260</td>\n",
       "      <td>NEU</td>\n",
       "      <td>198</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>055-1</td>\n",
       "      <td>~/Box Sync/DSI Documents/cleaned_data/cleaned_...</td>\n",
       "      <td>~/Box Sync/DSI Documents/Audio Files &amp; Tanscri...</td>\n",
       "      <td>let's go over the problems.</td>\n",
       "      <td>00:16.615</td>\n",
       "      <td>00:18.000</td>\n",
       "      <td>NEU</td>\n",
       "      <td>198</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                transcript_filepath  \\\n",
       "0  055-1  ~/Box Sync/DSI Documents/cleaned_data/cleaned_...   \n",
       "1  055-1  ~/Box Sync/DSI Documents/cleaned_data/cleaned_...   \n",
       "2  055-1  ~/Box Sync/DSI Documents/cleaned_data/cleaned_...   \n",
       "3  055-1  ~/Box Sync/DSI Documents/cleaned_data/cleaned_...   \n",
       "4  055-1  ~/Box Sync/DSI Documents/cleaned_data/cleaned_...   \n",
       "\n",
       "                                       wave_filename  \\\n",
       "0  ~/Box Sync/DSI Documents/Audio Files & Tanscri...   \n",
       "1  ~/Box Sync/DSI Documents/Audio Files & Tanscri...   \n",
       "2  ~/Box Sync/DSI Documents/Audio Files & Tanscri...   \n",
       "3  ~/Box Sync/DSI Documents/Audio Files & Tanscri...   \n",
       "4  ~/Box Sync/DSI Documents/Audio Files & Tanscri...   \n",
       "\n",
       "                                              speech start_timestamp  \\\n",
       "0    (okay) we are gonna go on and get started guys.       00:01.000   \n",
       "1  we are gonna do a little bit of reviewing with...       00:03.750   \n",
       "2  (now) keep in mind that we are playing the goo...       00:07.150   \n",
       "3                      everyone look up here please.       00:14.012   \n",
       "4                        let's go over the problems.       00:16.615   \n",
       "\n",
       "  end_timestamp label  transcriber_id Notes  \n",
       "0     00:03.380   NEU             198   NaN  \n",
       "1     00:06.763   NEU             198   NaN  \n",
       "2     00:12.769   NEU             198   NaN  \n",
       "3     00:16.260   NEU             198   NaN  \n",
       "4     00:18.000   NEU             198   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(207, 9)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print some info\n",
    "print('Using file:', available_csvs[0])\n",
    "\n",
    "#read dataframe and preview\n",
    "ts_df = pd.read_csv(available_csvs[0])\n",
    "display(ts_df.head())\n",
    "ts_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc29a97c",
   "metadata": {},
   "source": [
    "Things are looking as expected here.  We can clearly see that we'll have to do some work on the timestamp to get it into a sampling index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6844dc",
   "metadata": {},
   "source": [
    "## Conversion of timestamp to sampling index\n",
    "Here, we'll make some functions to help with the generation of the sampling index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a6d64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def timestamp2index(ts, round_type = 'ceil', sampling_rate=16000):\n",
    "    '''\n",
    "    Function timestamp2index: converts a timestamp with format dd:dd.ddd to an index given the sampling rate\n",
    "        ts: string of timestamp in\n",
    "        round_type (default 'ceil'): string of rounding to perform; can be 'ceil' or 'floor'\n",
    "        sampling_rate (default 16000): integer of the sampling rate (in Hz) of the audio\n",
    "    Returns: integer of index of converted timestamp or None if formatted incorrectly\n",
    "    '''\n",
    "    \n",
    "    #define regex\n",
    "    ts_pat = re.compile('(\\d{1,2}):(\\d{1,2}).(\\d{1,3})')\n",
    "    \n",
    "    #get the match\n",
    "    ts_match = ts_pat.match(ts)\n",
    "    \n",
    "    #throw a warning if you have issues\n",
    "    if ts_match is None:\n",
    "        warnings.warn('There is an issue with value: {0} and it could not be converted.'.format(ts))\n",
    "        return None\n",
    "    \n",
    "    #convert to full time (note that ljust zero pads on the right)\n",
    "    ts_seconds = 60*int(ts_match.group(1)) + int(ts_match.group(2)) + int(ts_match.group(3).ljust(3,'0'))/1000\n",
    "    \n",
    "    #identify rounding type\n",
    "    round_func = np.ceil\n",
    "    if round_type == 'floor':\n",
    "        round_func = np.floor\n",
    "\n",
    "    #create index and apply rounding\n",
    "    ts_ind = int(round_func(ts_seconds * sampling_rate))\n",
    "    \n",
    "    return ts_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a370bb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 00:00.000 Index: 0\n",
      "Timestamp: 01:00.000 Index: 960000\n",
      "Timestamp: 00:01.000 Index: 16000\n",
      "Timestamp: 00:00.500 Index: 8000\n",
      "Timestamp: 01:01.50 Index: 984000\n"
     ]
    }
   ],
   "source": [
    "#A few unit tests\n",
    "ts_utests = ['00:00.000',\n",
    "             '01:00.000',\n",
    "             '00:01.000',\n",
    "             '00:00.500',\n",
    "             '01:01.50']\n",
    "[print('Timestamp:', uts, 'Index:', timestamp2index(uts)) for uts in ts_utests];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c277ee2b",
   "metadata": {},
   "source": [
    "Fantastic.  This appears to work correctly.  Let's add this onto the data, then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86b71d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df['start_index'] = ts_df['start_timestamp'].apply(lambda x: timestamp2index(x, round_type='floor'))\n",
    "ts_df['end_index'] = ts_df['end_timestamp'].apply(lambda x: timestamp2index(x, round_type='ceil'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fd3d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>transcript_filepath</th>\n",
       "      <th>wave_filename</th>\n",
       "      <th>speech</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>end_timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>transcriber_id</th>\n",
       "      <th>Notes</th>\n",
       "      <th>start_index</th>\n",
       "      <th>end_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>055-1</td>\n",
       "      <td>~/Box Sync/DSI Documents/cleaned_data/cleaned_...</td>\n",
       "      <td>~/Box Sync/DSI Documents/Audio Files &amp; Tanscri...</td>\n",
       "      <td>(okay) we are gonna go on and get started guys.</td>\n",
       "      <td>00:01.000</td>\n",
       "      <td>00:03.380</td>\n",
       "      <td>NEU</td>\n",
       "      <td>198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000</td>\n",
       "      <td>54080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>055-1</td>\n",
       "      <td>~/Box Sync/DSI Documents/cleaned_data/cleaned_...</td>\n",
       "      <td>~/Box Sync/DSI Documents/Audio Files &amp; Tanscri...</td>\n",
       "      <td>we are gonna do a little bit of reviewing with...</td>\n",
       "      <td>00:03.750</td>\n",
       "      <td>00:06.763</td>\n",
       "      <td>NEU</td>\n",
       "      <td>198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60000</td>\n",
       "      <td>108208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>055-1</td>\n",
       "      <td>~/Box Sync/DSI Documents/cleaned_data/cleaned_...</td>\n",
       "      <td>~/Box Sync/DSI Documents/Audio Files &amp; Tanscri...</td>\n",
       "      <td>(now) keep in mind that we are playing the goo...</td>\n",
       "      <td>00:07.150</td>\n",
       "      <td>00:12.769</td>\n",
       "      <td>NEU</td>\n",
       "      <td>198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114400</td>\n",
       "      <td>204304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                transcript_filepath  \\\n",
       "0  055-1  ~/Box Sync/DSI Documents/cleaned_data/cleaned_...   \n",
       "1  055-1  ~/Box Sync/DSI Documents/cleaned_data/cleaned_...   \n",
       "2  055-1  ~/Box Sync/DSI Documents/cleaned_data/cleaned_...   \n",
       "\n",
       "                                       wave_filename  \\\n",
       "0  ~/Box Sync/DSI Documents/Audio Files & Tanscri...   \n",
       "1  ~/Box Sync/DSI Documents/Audio Files & Tanscri...   \n",
       "2  ~/Box Sync/DSI Documents/Audio Files & Tanscri...   \n",
       "\n",
       "                                              speech start_timestamp  \\\n",
       "0    (okay) we are gonna go on and get started guys.       00:01.000   \n",
       "1  we are gonna do a little bit of reviewing with...       00:03.750   \n",
       "2  (now) keep in mind that we are playing the goo...       00:07.150   \n",
       "\n",
       "  end_timestamp label  transcriber_id Notes  start_index  end_index  \n",
       "0     00:03.380   NEU             198   NaN        16000      54080  \n",
       "1     00:06.763   NEU             198   NaN        60000     108208  \n",
       "2     00:12.769   NEU             198   NaN       114400     204304  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8be5b09",
   "metadata": {},
   "source": [
    "Fantastic.  It looks like things are looking good in terms of reading the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8c37b5",
   "metadata": {},
   "source": [
    "## Adding on integer label\n",
    "We also need to have an integer label in the dataset.  Let's make and add that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05c6c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary\n",
    "label_dict = {0:\"PRS\", 1:\"OTR\", 2:\"NEU\", 3:\"REP\"}\n",
    "\n",
    "#Invert original\n",
    "rev_label_dict = {value:key for key, value in label_dict.items()}\n",
    "rev_label_dict\n",
    "\n",
    "#Substitute in dataframe\n",
    "ts_df['i_label'] = ts_df['label'].replace(rev_label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feecf0e-2998-4dea-a7c3-02c936d7616f",
   "metadata": {},
   "source": [
    "# Preparing Inputs to Model\n",
    "Here, we'll use the facebook wav2vec2 models, but we need to do some prep on the inputs to make sure things will go well.  Let's check it out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69fe1f4",
   "metadata": {},
   "source": [
    "## Split the data\n",
    "We're going to choose to just randomly split the data willy nilly.  Let's check this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f698346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_order</th>\n",
       "      <th>id</th>\n",
       "      <th>transcript_filepath</th>\n",
       "      <th>wave_filename</th>\n",
       "      <th>speech</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>end_timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>transcriber_id</th>\n",
       "      <th>Notes</th>\n",
       "      <th>start_index</th>\n",
       "      <th>end_index</th>\n",
       "      <th>i_label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>055-1</td>\n",
       "      <td>~/Box Sync/DSI Documents/cleaned_data/cleaned_...</td>\n",
       "      <td>~/Box Sync/DSI Documents/Audio Files &amp; Tanscri...</td>\n",
       "      <td>(okay) four plus two plus six.</td>\n",
       "      <td>05:02.843</td>\n",
       "      <td>05:06.045</td>\n",
       "      <td>OTR</td>\n",
       "      <td>198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4845488</td>\n",
       "      <td>4896720</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>055-1</td>\n",
       "      <td>~/Box Sync/DSI Documents/cleaned_data/cleaned_...</td>\n",
       "      <td>~/Box Sync/DSI Documents/Audio Files &amp; Tanscri...</td>\n",
       "      <td>nine.</td>\n",
       "      <td>01:16.100</td>\n",
       "      <td>01:16.852</td>\n",
       "      <td>NEU</td>\n",
       "      <td>198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1217600</td>\n",
       "      <td>1229632</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>055-1</td>\n",
       "      <td>~/Box Sync/DSI Documents/cleaned_data/cleaned_...</td>\n",
       "      <td>~/Box Sync/DSI Documents/Audio Files &amp; Tanscri...</td>\n",
       "      <td>name?</td>\n",
       "      <td>01:14.500</td>\n",
       "      <td>01:15.302</td>\n",
       "      <td>OTR</td>\n",
       "      <td>198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1192000</td>\n",
       "      <td>1204832</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true_order     id                                transcript_filepath  \\\n",
       "0          99  055-1  ~/Box Sync/DSI Documents/cleaned_data/cleaned_...   \n",
       "1          24  055-1  ~/Box Sync/DSI Documents/cleaned_data/cleaned_...   \n",
       "2          23  055-1  ~/Box Sync/DSI Documents/cleaned_data/cleaned_...   \n",
       "\n",
       "                                       wave_filename  \\\n",
       "0  ~/Box Sync/DSI Documents/Audio Files & Tanscri...   \n",
       "1  ~/Box Sync/DSI Documents/Audio Files & Tanscri...   \n",
       "2  ~/Box Sync/DSI Documents/Audio Files & Tanscri...   \n",
       "\n",
       "                           speech start_timestamp end_timestamp label  \\\n",
       "0  (okay) four plus two plus six.       05:02.843     05:06.045   OTR   \n",
       "1                           nine.       01:16.100     01:16.852   NEU   \n",
       "2                           name?       01:14.500     01:15.302   OTR   \n",
       "\n",
       "   transcriber_id Notes  start_index  end_index  i_label  split  \n",
       "0             198   NaN      4845488    4896720        1      0  \n",
       "1             198   NaN      1217600    1229632        2      0  \n",
       "2             198   NaN      1192000    1204832        1      0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#randomly permute\n",
    "arr_df = ts_df.sample(frac=1, random_state=2021)\n",
    "\n",
    "#assign split based on physical location after reordering\n",
    "arr_df = arr_df.reset_index()\n",
    "arr_df = arr_df.rename(columns={'index':'true_order'})\n",
    "arr_df['split'] = (arr_df.index>np.ceil(len(arr_df)*0.8)).astype(int)\n",
    "arr_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2e7a58",
   "metadata": {},
   "source": [
    "## Pre-process audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9718d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read audio data\n",
    "class_audio, class_sr = sf.read(audio_dir + test_audio_id + '.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c55e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get subsets of audio as a list\n",
    "audio_clips_train = [class_audio[start:end] for start, end in arr_df.query('split==0')[['start_index', 'end_index']].values]\n",
    "audio_clips_test = [class_audio[start:end] for start, end in arr_df.query('split==1')[['start_index', 'end_index']].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7e7e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n",
      "51232\n",
      "40\n",
      "167952\n"
     ]
    }
   ],
   "source": [
    "#this looks about right\n",
    "print(len(audio_clips_train))\n",
    "print(len(audio_clips_train[0]))\n",
    "print(len(audio_clips_test))\n",
    "print(len(audio_clips_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869adeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abaa115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process inputs appropriately\n",
    "train_inputs = processor(audio_clips_train, return_tensors=\"pt\", padding=\"longest\", sampling_rate=sampling_rate)\n",
    "test_inputs = processor(audio_clips_test, return_tensors=\"pt\", padding=\"longest\", sampling_rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f68160",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "Now, we have all of our inputs ready, let's try to train this model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e0b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helpers for class size and class names\n",
    "no_classes = len(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1538936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create custom Datasets Class\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "#Create datasets from encodings\n",
    "train_dataset = CustomDataset(train_inputs, arr_df.query('split==0')['i_label'].tolist())\n",
    "val_dataset = CustomDataset(test_inputs, arr_df.query('split==1')['i_label'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e57d6aa",
   "metadata": {},
   "source": [
    "## Create model for task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169dbd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['classifier.weight', 'projector.bias', 'wav2vec2.masked_spec_embed', 'classifier.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(\"facebook/wav2vec2-base-960h\", num_labels=no_classes, id2label=label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f261ef84",
   "metadata": {},
   "source": [
    "We see the error above and we're happy to see it.  This means that we've added the \"Sequence Classification\" part onto the base and it realizes that the assigned weights are meaningless.  Perfect!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44efbf00",
   "metadata": {},
   "source": [
    "## Setup and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248d432",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters around training\n",
    "training_args = TrainingArguments(\"test_trainer\",\n",
    "                                  num_train_epochs = 3,\n",
    "                                  logging_strategy='epoch', \n",
    "                                  evaluation_strategy='epoch',\n",
    "                                  per_device_train_batch_size=3,\n",
    "                                  per_device_eval_batch_size=3,\n",
    "                                  report_to='all'\n",
    "                                 )\n",
    "\n",
    "#define the metric; we use accuracy here but we shouldn't\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "#function to calculate metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bdd77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 167\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n",
      "/tmp/ipykernel_28630/2552555029.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.326400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.239000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.193500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=63, training_loss=1.2529784005785745, metrics={'train_runtime': 38.9867, 'train_samples_per_second': 12.851, 'train_steps_per_second': 1.616, 'total_flos': 3.905273132082662e+16, 'train_loss': 1.2529784005785745, 'epoch': 3.0})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=processor,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40765453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 40\n",
      "  Batch size = 8\n",
      "/tmp/ipykernel_28630/2552555029.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1072285175323486,\n",
       " 'eval_accuracy': 0.55,\n",
       " 'eval_runtime': 2.1104,\n",
       " 'eval_samples_per_second': 18.954,\n",
       " 'eval_steps_per_second': 2.369,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5244d22a",
   "metadata": {},
   "source": [
    "Well!  This is pretty exciting!  We can train the model, which is great!  The performance, on the other hand, is terrible.  There are many ways I think this can be remedied, the first of which would be running more epochs.  We'll take a look!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
