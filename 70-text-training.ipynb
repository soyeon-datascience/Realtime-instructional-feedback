{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 70-text-training\n",
    "> Training models\n",
    "\n",
    "In this notebook, I fine-tuned the model \"bert-base-cased\" using tokenizer encodings. 80% of original data is used as training data, and 10% of the original data is used as test data. This fine-tuend model shows 93% accuracy on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from datasets import load_dataset, load_metric, Dataset\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import torch\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we're going to use directly load the full CSV of all of the data and use it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I imported \"final_add_split.csv\" file from my own ACCRE. You should change the path of the file.\n",
    "base_prefix = os.path.expanduser('/data/p_dsi/wise/data/cleaned_data/')\n",
    "file_dir = base_prefix + 'final_csv_wsplits.csv'\n",
    "data = pd.read_csv(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>transcript_filepath</th>\n",
       "      <th>wave_filename</th>\n",
       "      <th>speech</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>end_timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>transcriber_id</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135-2</td>\n",
       "      <td>~ise/data/cleaned_data/cleaned_transcripts/135...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Tanscripts...</td>\n",
       "      <td>if we do 100 and we use the power of ten we mu...</td>\n",
       "      <td>00:01:05.04</td>\n",
       "      <td>00:02:02.05</td>\n",
       "      <td>OTR</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>252-1</td>\n",
       "      <td>~ise/data/cleaned_data/cleaned_transcripts/252...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Tanscripts...</td>\n",
       "      <td>raise your fingers.</td>\n",
       "      <td>00:06:14.05</td>\n",
       "      <td>00:07:18.00</td>\n",
       "      <td>OTR</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116-3</td>\n",
       "      <td>~ise/data/cleaned_data/cleaned_transcripts/116...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Tanscripts...</td>\n",
       "      <td>well you know what I will take this.</td>\n",
       "      <td>00:02:03.24</td>\n",
       "      <td>00:04:05.01</td>\n",
       "      <td>NEU</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>251-1</td>\n",
       "      <td>~ise/data/cleaned_data/cleaned_transcripts/251...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Tanscripts...</td>\n",
       "      <td>the body.</td>\n",
       "      <td>00:08:09.01</td>\n",
       "      <td>00:10:02.02</td>\n",
       "      <td>NEU</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>252-2</td>\n",
       "      <td>~ise/data/cleaned_data/cleaned_transcripts/252...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Tanscripts...</td>\n",
       "      <td>I'm gonna actually underline these two sentenc...</td>\n",
       "      <td>00:06:09.00</td>\n",
       "      <td>00:07:35.27</td>\n",
       "      <td>NEU</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                transcript_filepath  \\\n",
       "0  135-2  ~ise/data/cleaned_data/cleaned_transcripts/135...   \n",
       "1  252-1  ~ise/data/cleaned_data/cleaned_transcripts/252...   \n",
       "2  116-3  ~ise/data/cleaned_data/cleaned_transcripts/116...   \n",
       "3  251-1  ~ise/data/cleaned_data/cleaned_transcripts/251...   \n",
       "4  252-2  ~ise/data/cleaned_data/cleaned_transcripts/252...   \n",
       "\n",
       "                                       wave_filename  \\\n",
       "0  /data/p_dsi/wise/data/Audio Files & Tanscripts...   \n",
       "1  /data/p_dsi/wise/data/Audio Files & Tanscripts...   \n",
       "2  /data/p_dsi/wise/data/Audio Files & Tanscripts...   \n",
       "3  /data/p_dsi/wise/data/Audio Files & Tanscripts...   \n",
       "4  /data/p_dsi/wise/data/Audio Files & Tanscripts...   \n",
       "\n",
       "                                              speech start_timestamp  \\\n",
       "0  if we do 100 and we use the power of ten we mu...     00:01:05.04   \n",
       "1                                raise your fingers.     00:06:14.05   \n",
       "2               well you know what I will take this.     00:02:03.24   \n",
       "3                                          the body.     00:08:09.01   \n",
       "4  I'm gonna actually underline these two sentenc...     00:06:09.00   \n",
       "\n",
       "  end_timestamp label  transcriber_id  split  \n",
       "0   00:02:02.05   OTR             198      0  \n",
       "1   00:07:18.00   OTR             198      0  \n",
       "2   00:04:05.01   NEU             198      0  \n",
       "3   00:10:02.02   NEU             198      0  \n",
       "4   00:07:35.27   NEU             198      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a computer understand each label, labels such as \"PRS\" and \"REP\" should be converted to a numerical value. Therefore we are going to make a new column called \"label_digit\" and we are going to assign a value like this:\n",
    "\n",
    "- PRS : 0\n",
    "- REP : 1\n",
    "- NEU : 2\n",
    "- OTR : 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column 'label_digit' to convert classes' type into numbers.\n",
    "conditions = [\n",
    "    (data['label'] == \"PRS\"),\n",
    "    (data['label'] == 'REP'),\n",
    "    (data['label'] == 'NEU'),\n",
    "    (data['label'] == \"OTR\")\n",
    "    ]\n",
    "\n",
    "values = [0, 1, 2, 3]\n",
    "\n",
    "data['label_digit'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>transcript_filepath</th>\n",
       "      <th>wave_filename</th>\n",
       "      <th>speech</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>end_timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>transcriber_id</th>\n",
       "      <th>split</th>\n",
       "      <th>label_digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135-2</td>\n",
       "      <td>~ise/data/cleaned_data/cleaned_transcripts/135...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Tanscripts...</td>\n",
       "      <td>if we do 100 and we use the power of ten we mu...</td>\n",
       "      <td>00:01:05.04</td>\n",
       "      <td>00:02:02.05</td>\n",
       "      <td>OTR</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>252-1</td>\n",
       "      <td>~ise/data/cleaned_data/cleaned_transcripts/252...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Tanscripts...</td>\n",
       "      <td>raise your fingers.</td>\n",
       "      <td>00:06:14.05</td>\n",
       "      <td>00:07:18.00</td>\n",
       "      <td>OTR</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116-3</td>\n",
       "      <td>~ise/data/cleaned_data/cleaned_transcripts/116...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Tanscripts...</td>\n",
       "      <td>well you know what I will take this.</td>\n",
       "      <td>00:02:03.24</td>\n",
       "      <td>00:04:05.01</td>\n",
       "      <td>NEU</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>251-1</td>\n",
       "      <td>~ise/data/cleaned_data/cleaned_transcripts/251...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Tanscripts...</td>\n",
       "      <td>the body.</td>\n",
       "      <td>00:08:09.01</td>\n",
       "      <td>00:10:02.02</td>\n",
       "      <td>NEU</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>252-2</td>\n",
       "      <td>~ise/data/cleaned_data/cleaned_transcripts/252...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Tanscripts...</td>\n",
       "      <td>I'm gonna actually underline these two sentenc...</td>\n",
       "      <td>00:06:09.00</td>\n",
       "      <td>00:07:35.27</td>\n",
       "      <td>NEU</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                transcript_filepath  \\\n",
       "0  135-2  ~ise/data/cleaned_data/cleaned_transcripts/135...   \n",
       "1  252-1  ~ise/data/cleaned_data/cleaned_transcripts/252...   \n",
       "2  116-3  ~ise/data/cleaned_data/cleaned_transcripts/116...   \n",
       "3  251-1  ~ise/data/cleaned_data/cleaned_transcripts/251...   \n",
       "4  252-2  ~ise/data/cleaned_data/cleaned_transcripts/252...   \n",
       "\n",
       "                                       wave_filename  \\\n",
       "0  /data/p_dsi/wise/data/Audio Files & Tanscripts...   \n",
       "1  /data/p_dsi/wise/data/Audio Files & Tanscripts...   \n",
       "2  /data/p_dsi/wise/data/Audio Files & Tanscripts...   \n",
       "3  /data/p_dsi/wise/data/Audio Files & Tanscripts...   \n",
       "4  /data/p_dsi/wise/data/Audio Files & Tanscripts...   \n",
       "\n",
       "                                              speech start_timestamp  \\\n",
       "0  if we do 100 and we use the power of ten we mu...     00:01:05.04   \n",
       "1                                raise your fingers.     00:06:14.05   \n",
       "2               well you know what I will take this.     00:02:03.24   \n",
       "3                                          the body.     00:08:09.01   \n",
       "4  I'm gonna actually underline these two sentenc...     00:06:09.00   \n",
       "\n",
       "  end_timestamp label  transcriber_id  split  label_digit  \n",
       "0   00:02:02.05   OTR             198      0            3  \n",
       "1   00:07:18.00   OTR             198      0            3  \n",
       "2   00:04:05.01   NEU             198      0            2  \n",
       "3   00:10:02.02   NEU             198      0            2  \n",
       "4   00:07:35.27   NEU             198      0            2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer is a translator from human-readable text, to transformer readable tokens. In this notebook, we are going to use pretrained Tokenizer \"bert-base-cased\".                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize inputs and convert to PyTorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tokenized representations\n",
    "train_text = data.query('split==0')['speech'].tolist()\n",
    "test_text = data.query('split==1')['speech'].tolist()\n",
    "val_text = data.query('split==2')['speech'].tolist()\n",
    "\n",
    "train_encodings = tokenizer(train_text, truncation=True, padding='longest')\n",
    "test_encodings = tokenizer(test_text, truncation=True, padding='longest')\n",
    "val_encodings = tokenizer(val_text, truncation=True, padding='longest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helpers for class size and class names\n",
    "no_classes = len(data.query('split==0')['label_digit'].unique())\n",
    "label_dict = {0:\"PRS\", 1:\"REP\", 2:\"NEU\", 3:\"OTR\"}\n",
    "train_classes = [label_dict[class_ind] for class_ind in range(no_classes)]\n",
    "formal_labels = [\"praise\", \"reprimand\", \"neutral\", \"opportunity to respond\"]\n",
    "rev_labels_lookup = dict(zip(train_classes, formal_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "{0: 'PRS', 1: 'REP', 2: 'NEU', 3: 'OTR'}\n",
      "['PRS', 'REP', 'NEU', 'OTR']\n",
      "['praise', 'reprimand', 'neutral', 'opportunity to respond']\n",
      "{'PRS': 'praise', 'REP': 'reprimand', 'NEU': 'neutral', 'OTR': 'opportunity to respond'}\n"
     ]
    }
   ],
   "source": [
    "print(no_classes)\n",
    "print(label_dict)\n",
    "print(train_classes)\n",
    "print(formal_labels)\n",
    "print(rev_labels_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's pass our labels and encodings to a Dataset object. We put the data in this format so that the data can be easily batched such that each key in the batch encoding corresponds to a named parameter of the forward() method of the model we will train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create custom Datasets Class\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "#Create datasets from encodings\n",
    "train_dataset = CustomDataset(train_encodings, data.query('split==0')['label_digit'].tolist())\n",
    "test_dataset = CustomDataset(test_encodings, data.query('split==1')['label_digit'].tolist())\n",
    "val_dataset = CustomDataset(val_encodings, data.query('split==2')['label_digit'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model for task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model, we are going to use pretrained model called \"bert-base-cased\". Using our dataset, we are going to fine-tune this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=no_classes, id2label=label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\"test_trainer\", logging_strategy='epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we use _accuracy_ as the metric for our model to assess performance during evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train the model. During the 3 epochs, the training model made 2103 steps. As you can see below, the training loss is getting smaller as the model make a step. This means our model is learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 11206\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2103\n",
      "/data/p_dsi/wise/env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2103' max='2103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2103/2103 06:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>701</td>\n",
       "      <td>0.523700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1402</td>\n",
       "      <td>0.337300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2103</td>\n",
       "      <td>0.213300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test_trainer/checkpoint-500\n",
      "Configuration saved in test_trainer/checkpoint-500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in test_trainer/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in test_trainer/checkpoint-500/special_tokens_map.json\n",
      "/data/p_dsi/wise/env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test_trainer/checkpoint-1000\n",
      "Configuration saved in test_trainer/checkpoint-1000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in test_trainer/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in test_trainer/checkpoint-1000/special_tokens_map.json\n",
      "/data/p_dsi/wise/env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test_trainer/checkpoint-1500\n",
      "Configuration saved in test_trainer/checkpoint-1500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in test_trainer/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in test_trainer/checkpoint-1500/special_tokens_map.json\n",
      "/data/p_dsi/wise/env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to test_trainer/checkpoint-2000\n",
      "Configuration saved in test_trainer/checkpoint-2000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in test_trainer/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in test_trainer/checkpoint-2000/special_tokens_map.json\n",
      "/data/p_dsi/wise/env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2103, training_loss=0.35807597858249374, metrics={'train_runtime': 410.7196, 'train_samples_per_second': 81.851, 'train_steps_per_second': 5.12, 'total_flos': 1261164296004912.0, 'train_loss': 0.35807597858249374, 'epoch': 3.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model finally finished leanring! Let's evaluated our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 11206\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1402' max='701' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [701/701 02:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.1384349763393402,\n",
       " 'eval_accuracy': 0.954577904693914,\n",
       " 'eval_runtime': 66.539,\n",
       " 'eval_samples_per_second': 168.412,\n",
       " 'eval_steps_per_second': 10.535,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Saving\n",
    "\n",
    "Note that after we've saved the model below, we'll be able to use the pipeline function to load this model and use it for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to bert-teacher-saying-classifier\n",
      "Configuration saved in bert-teacher-saying-classifier/config.json\n",
      "Model weights saved in bert-teacher-saying-classifier/pytorch_model.bin\n",
      "tokenizer config file saved in bert-teacher-saying-classifier/tokenizer_config.json\n",
      "Special tokens file saved in bert-teacher-saying-classifier/special_tokens_map.json\n",
      "loading configuration file bert-teacher-saying-classifier/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"PRS\",\n",
      "    \"1\": \"REP\",\n",
      "    \"2\": \"NEU\",\n",
      "    \"3\": \"OTR\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.10.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading configuration file bert-teacher-saying-classifier/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"PRS\",\n",
      "    \"1\": \"REP\",\n",
      "    \"2\": \"NEU\",\n",
      "    \"3\": \"OTR\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.10.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file bert-teacher-saying-classifier/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at bert-teacher-saying-classifier.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "Didn't find file bert-teacher-saying-classifier/added_tokens.json. We won't load it.\n",
      "loading file bert-teacher-saying-classifier/vocab.txt\n",
      "loading file bert-teacher-saying-classifier/tokenizer.json\n",
      "loading file None\n",
      "loading file bert-teacher-saying-classifier/special_tokens_map.json\n",
      "loading file bert-teacher-saying-classifier/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('bert-teacher-saying-classifier')\n",
    "teacher_classifier = pipeline('text-classification', model='bert-teacher-saying-classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix using validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we used training dataset to train the model. From here, we are going to use only the validation dataset to see how accurate our model's predictions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict labels of validation dataset\n",
    "val_pred = teacher_classifier(val_text)\n",
    "# Convert list into dataframe\n",
    "val_pred_df = pd.DataFrame(val_pred)\n",
    "# Change the column's name (label -> predict)\n",
    "val_pred_df.rename(columns = {'label':'predict'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see each speech's predicted result by our model and actual label. \"score\" refers to confidence level. The higher the score is, the more confident our model has about it's prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>end_timestamp</th>\n",
       "      <th>speech</th>\n",
       "      <th>label</th>\n",
       "      <th>predict</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>251-2</td>\n",
       "      <td>00:01:33.15</td>\n",
       "      <td>00:03:26.16</td>\n",
       "      <td>you can think of one.</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>0.985349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>046-1</td>\n",
       "      <td>00:01:52.06</td>\n",
       "      <td>00:02:32.04</td>\n",
       "      <td>she can't play jokes like character can can she.</td>\n",
       "      <td>OTR</td>\n",
       "      <td>OTR</td>\n",
       "      <td>0.967072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>264-3</td>\n",
       "      <td>00:00:00.00</td>\n",
       "      <td>00:02:20.25</td>\n",
       "      <td>{shh}.</td>\n",
       "      <td>REP</td>\n",
       "      <td>REP</td>\n",
       "      <td>0.960794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>251-2</td>\n",
       "      <td>00:01:33.15</td>\n",
       "      <td>00:03:26.16</td>\n",
       "      <td>how do you know surfing?</td>\n",
       "      <td>OTR</td>\n",
       "      <td>OTR</td>\n",
       "      <td>0.983423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>083-3</td>\n",
       "      <td>00:03:59.23</td>\n",
       "      <td>00:06:36.02</td>\n",
       "      <td>bravely.</td>\n",
       "      <td>OTR</td>\n",
       "      <td>OTR</td>\n",
       "      <td>0.985749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id start_timestamp end_timestamp  \\\n",
       "0  251-2     00:01:33.15   00:03:26.16   \n",
       "1  046-1     00:01:52.06   00:02:32.04   \n",
       "2  264-3     00:00:00.00   00:02:20.25   \n",
       "3  251-2     00:01:33.15   00:03:26.16   \n",
       "4  083-3     00:03:59.23   00:06:36.02   \n",
       "\n",
       "                                             speech label predict     score  \n",
       "0                             you can think of one.   NEU     NEU  0.985349  \n",
       "1  she can't play jokes like character can can she.   OTR     OTR  0.967072  \n",
       "2                                            {shh}.   REP     REP  0.960794  \n",
       "3                          how do you know surfing?   OTR     OTR  0.983423  \n",
       "4                                          bravely.   OTR     OTR  0.985749  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the true label and speech\n",
    "val_true = data[data.split == 2][[\"id\", \"start_timestamp\", \"end_timestamp\", \"speech\", \"label\"]]\n",
    "val_true.reset_index(inplace = True, drop = True)\n",
    "\n",
    "# Combine two dataframe\n",
    "val_final_df = pd.concat([val_true, val_pred_df], axis = 1)\n",
    "val_final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a confusion matrix using predicted labels and actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_ma = confusion_matrix(val_final_df['label'], val_final_df['predict'], labels = train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted Labels</th>\n",
       "      <th>praise</th>\n",
       "      <th>reprimand</th>\n",
       "      <th>neutral</th>\n",
       "      <th>opportunity to respond</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>praise</th>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reprimand</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>756</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opportunity to respond</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted Labels        praise  reprimand  neutral  opportunity to respond\n",
       "Actual Labels                                                             \n",
       "praise                     163          0        8                       1\n",
       "reprimand                    1         38       11                       1\n",
       "neutral                     13          6      756                      34\n",
       "opportunity to respond       1          0       26                     342"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_df = pd.DataFrame(c_ma,\n",
    "                    columns = train_classes,\n",
    "                    index = train_classes)\n",
    "\n",
    "#use reverse lookup table from above to use the actual labels that we assigned for zero shot\n",
    "c_df.rename(columns=rev_labels_lookup, index=rev_labels_lookup, inplace=True)\n",
    "\n",
    "#add axis labels for seaborn\n",
    "c_df.index.name = 'Actual Labels'\n",
    "c_df.columns.name = 'Predicted Labels'\n",
    "\n",
    "#inspect\n",
    "c_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to increase readability, let's use color to express this table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#use seaborne to display as heatmap\n",
    "ax = sns.heatmap(c_df, cmap='Blues', annot=True, fmt='d');\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation = 45);\n",
    "ax.set_yticklabels(ax.get_yticklabels(),rotation = 45);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The x-axis shows the predicted labels and the y-axis shows the actual labels. \n",
    "\n",
    "Let's inspect this confusion matrix:\n",
    "- This fine-tuned model did a quite good job to classify labels. Diagonal line from the right bottom to left top is the number of speech classfied correctly. We can see that most of speech belongs to this area.\n",
    "- Among the misclassified area, the highest number is 34. This is when \"neutral\" speech is classified as \"opportunity to respond\". The second highest number is 26 and this is when \"opportunity to respond\" speech is classified as \"neutral\". These two situations show that our model is confused with \"neutral\" and \"opportunity to respond\" the most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great steps to improve from here include:\n",
    "- In the dataset, the number of \"neutral\" speech outweigh that of other speechs. It would be better to train a model to discern between neutral and other classes first and then classify other labels.\n",
    "- We can consider setting a specific cutoff number to decide if it is either \"OTR\" or \"NEU\". For example, if the probability is more than the cutoff number, then the prediction will be \"OTR\". Even if our model predicts a speech as \"OTR\", but the probability is lower than the cutoff number, the model should predict it as \"NEU\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Performance Using Classification Report\n",
    "\n",
    "Here, we'll just use the classification report function from sklearn. This will return the precision (positive predictive value), recall (sensitivity), and f1 score (harmonic mean of precision and recall) and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                praise       0.92      0.95      0.93       172\n",
      "             reprimand       0.86      0.75      0.80        51\n",
      "               neutral       0.94      0.93      0.94       809\n",
      "opportunity to respond       0.90      0.93      0.92       369\n",
      "\n",
      "              accuracy                           0.93      1401\n",
      "             macro avg       0.91      0.89      0.90      1401\n",
      "          weighted avg       0.93      0.93      0.93      1401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perf_metrics = classification_report(val_final_df.dropna()['label'], val_final_df.dropna()['predict'], labels=train_classes, target_names = formal_labels)\n",
    "print(perf_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compared to other labels, 'reprimand' shows a low sensitivity. While other label's sensitivity is more than 0.9, that of 'reprimand' is 0.75. When we go back to the confusion matrix, there are 51 reprimand speech in the validation dataset. Among them, only 38 is correctly discerned, while 11s are misclassified as \"NEU\".\n",
    "- This model's accuracy is 93%. In the 90 notebook, when we used \"facebook/bart-large-mnli\" model, the accuracy was 47%. When we used \"typeform/distilbert-base-uncased-mnli\" model in 93 notebook, the accuracy was 32%. Compared to these results from other models, this fine-tuned shows a really high accuracy. We can say that the process of fine-tuning improved the performance of a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine validation dataset's misclassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's focus on misclassified speech. The outcome below shows the misclassified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misclassfication\n",
    "val_error = val_final_df[val_final_df.label != val_final_df.predict]\n",
    "val_error = val_error.sort_values(by = 'score', ascending = False)\n",
    "#val_error.to_csv(\"val_error.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>end_timestamp</th>\n",
       "      <th>speech</th>\n",
       "      <th>label</th>\n",
       "      <th>predict</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>108-2</td>\n",
       "      <td>00:07:39.24</td>\n",
       "      <td>00:10:01.08</td>\n",
       "      <td>they're ready for the day (th*) to continue.</td>\n",
       "      <td>PRS</td>\n",
       "      <td>NEU</td>\n",
       "      <td>0.998124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>123-2</td>\n",
       "      <td>00:04:09.21</td>\n",
       "      <td>00:05:42.00</td>\n",
       "      <td>so (everybody sai*) everybody agreed that it w...</td>\n",
       "      <td>OTR</td>\n",
       "      <td>NEU</td>\n",
       "      <td>0.997607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>088-1</td>\n",
       "      <td>00:02:51.00</td>\n",
       "      <td>00:04:09.17</td>\n",
       "      <td>now let's think about where this story took pl...</td>\n",
       "      <td>OTR</td>\n",
       "      <td>NEU</td>\n",
       "      <td>0.997555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>254-1</td>\n",
       "      <td>00:01:21.04</td>\n",
       "      <td>00:02:00.10</td>\n",
       "      <td>excellent thoughts from all three of you guys.</td>\n",
       "      <td>OTR</td>\n",
       "      <td>PRS</td>\n",
       "      <td>0.996845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>083-1</td>\n",
       "      <td>00:03:23.24</td>\n",
       "      <td>00:05:58.22</td>\n",
       "      <td>(now) see you can do it faster.</td>\n",
       "      <td>PRS</td>\n",
       "      <td>NEU</td>\n",
       "      <td>0.995130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>273-2</td>\n",
       "      <td>00:08:23.00</td>\n",
       "      <td>00:09:09.08</td>\n",
       "      <td>person place.</td>\n",
       "      <td>OTR</td>\n",
       "      <td>NEU</td>\n",
       "      <td>0.994964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>254-1</td>\n",
       "      <td>00:05:18.21</td>\n",
       "      <td>00:06:34.00</td>\n",
       "      <td>(what else) what else can we guess.</td>\n",
       "      <td>PRS</td>\n",
       "      <td>OTR</td>\n",
       "      <td>0.992825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>116-1</td>\n",
       "      <td>00:02:26.25</td>\n",
       "      <td>00:03:20.08</td>\n",
       "      <td>let's do our character.</td>\n",
       "      <td>OTR</td>\n",
       "      <td>NEU</td>\n",
       "      <td>0.991830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>123-1</td>\n",
       "      <td>00:00:00.00</td>\n",
       "      <td>00:02:10.25</td>\n",
       "      <td>what?</td>\n",
       "      <td>NEU</td>\n",
       "      <td>OTR</td>\n",
       "      <td>0.991740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>107-3</td>\n",
       "      <td>00:00:00.00</td>\n",
       "      <td>00:02:12.05</td>\n",
       "      <td>oh yeah?</td>\n",
       "      <td>OTR</td>\n",
       "      <td>NEU</td>\n",
       "      <td>0.991722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id start_timestamp end_timestamp  \\\n",
       "685   108-2     00:07:39.24   00:10:01.08   \n",
       "869   123-2     00:04:09.21   00:05:42.00   \n",
       "237   088-1     00:02:51.00   00:04:09.17   \n",
       "1253  254-1     00:01:21.04   00:02:00.10   \n",
       "807   083-1     00:03:23.24   00:05:58.22   \n",
       "225   273-2     00:08:23.00   00:09:09.08   \n",
       "1023  254-1     00:05:18.21   00:06:34.00   \n",
       "694   116-1     00:02:26.25   00:03:20.08   \n",
       "771   123-1     00:00:00.00   00:02:10.25   \n",
       "1335  107-3     00:00:00.00   00:02:12.05   \n",
       "\n",
       "                                                 speech label predict  \\\n",
       "685        they're ready for the day (th*) to continue.   PRS     NEU   \n",
       "869   so (everybody sai*) everybody agreed that it w...   OTR     NEU   \n",
       "237   now let's think about where this story took pl...   OTR     NEU   \n",
       "1253     excellent thoughts from all three of you guys.   OTR     PRS   \n",
       "807                     (now) see you can do it faster.   PRS     NEU   \n",
       "225                                       person place.   OTR     NEU   \n",
       "1023                (what else) what else can we guess.   PRS     OTR   \n",
       "694                             let's do our character.   OTR     NEU   \n",
       "771                                               what?   NEU     OTR   \n",
       "1335                                           oh yeah?   OTR     NEU   \n",
       "\n",
       "         score  \n",
       "685   0.998124  \n",
       "869   0.997607  \n",
       "237   0.997555  \n",
       "1253  0.996845  \n",
       "807   0.995130  \n",
       "225   0.994964  \n",
       "1023  0.992825  \n",
       "694   0.991830  \n",
       "771   0.991740  \n",
       "1335  0.991722  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_error.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After examinig the misclassified dataset, I realized that there are some speech of which actual \"label\" is wrong. This means when people manually gave groundtruth label to speech lines, they made a mistake to some speech lines. \n",
    "\n",
    "When you look at a speech with index 1253 in the dataset above, the label is \"OTR\", even though the speech \"excellent thoughts from all three of you guys.\" is absolutely \"PRS\", which is \"praise\". Our model predicted this speech as \"PRS\", which I think it is correct. There are more examples of these \"wrong\" labels, which our model predicts, I think, correctly. For this reason, we should look at our misclassified data and increase the quality of the raw data, by correcting some labels while listening the audio files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
