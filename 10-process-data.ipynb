{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-process-data\n",
    "> Importing, cleaning, testing, and saving data\n",
    "\n",
    "This notebook has mainly two functions:\n",
    "1. It cleans docx file (remove 't', '.c' from speech lines)\n",
    "2. It converts docx files to csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful packages and preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_no_test\n",
    "#default_exp text_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# data access and processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# File helpers\n",
    "import glob\n",
    "\n",
    "# python helpers\n",
    "import os.path\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "# docx helpers\n",
    "import docx\n",
    "import docx2txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the file path\n",
    "You can change 'base_prefix' variable below according to your computer environment. In this example, Soyeon's local file path was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_prefix = os.path.expanduser('~/Box Sync/DSI Documents/')\n",
    "base_prefix = '/data/p_dsi/wise/data/'\n",
    "file_directory = base_prefix + 'Audio Files & Tanscripts/Transcripts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning docx files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define getText() function to import docx into text in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def getText(filename):\n",
    "    \"\"\"\n",
    "    Import document file and show in python environment\n",
    "    \n",
    "    Parmeters\n",
    "    ---------\n",
    "    filename : str\n",
    "        a document's file path\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        the document's contents\n",
    "    \"\"\"\n",
    "    doc = docx.Document(filename)\n",
    "    fullText = []\n",
    "    for para in doc.paragraphs:\n",
    "        fullText.append(para.text)\n",
    "    return '\\n'.join(fullText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read all transcripts and convert them into Pandas Data frame with text in Python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123-1-198</td>\n",
       "      <td>- 00:00:00.00\\nt uhhuh [SI-0] [INF]. {NEU}\\nc ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>046-2-198</td>\n",
       "      <td>- 00:00:00.00\\nuhhuh. {NEU}\\n(okay) you're col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>273-1-198</td>\n",
       "      <td>- 00:00:00.00\\nt today we're talking about the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>083-1-198</td>\n",
       "      <td>-00:00:00.00  \\nt ready [SI-0]? {OTR}\\nc .\\nt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108-2-198</td>\n",
       "      <td>- 00:00:00.00\\nt (okay) we're gonna be talkin ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_id                                               text\n",
       "0  123-1-198  - 00:00:00.00\\nt uhhuh [SI-0] [INF]. {NEU}\\nc ...\n",
       "1  046-2-198  - 00:00:00.00\\nuhhuh. {NEU}\\n(okay) you're col...\n",
       "2  273-1-198  - 00:00:00.00\\nt today we're talking about the...\n",
       "3  083-1-198  -00:00:00.00  \\nt ready [SI-0]? {OTR}\\nc .\\nt ...\n",
       "4  108-2-198  - 00:00:00.00\\nt (okay) we're gonna be talkin ..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get filenames list\n",
    "filenames = glob.glob(file_directory + '/*.docx')\n",
    "\n",
    "# read file contents\n",
    "file_contents = []\n",
    "file_id = []\n",
    "for file in filenames:\n",
    "    file_id.append(file.split(\"/\")[-1].split(\" \")[0])\n",
    "    file_contents.append(getText(file))\n",
    "    \n",
    "# convert to df\n",
    "file_df = pd.DataFrame({'file_id': file_id, 'text': file_contents})\n",
    "file_df.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Strip t and .c and remove all [*] inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(file_df.shape[0]):\n",
    "    strip_text = []\n",
    "    for line in file_df.loc[i, \"text\"].split(\"\\n\"):\n",
    "        if line[:2] == \"t \":\n",
    "            new = line[2:]\n",
    "        elif line[:3] == \"c .\":\n",
    "            continue\n",
    "        else:\n",
    "            new = line\n",
    "        strip_text.append(new)\n",
    "    strip_text = \"\\n\".join(strip_text)\n",
    "    file_df.loc[i, \"strip_text\"] = strip_text\n",
    "\n",
    "\n",
    "for i in range(file_df.shape[0]):\n",
    "    strip_text = []\n",
    "    for line in file_df.loc[i, \"strip_text\"].split(\"\\n\"):\n",
    "        new = re.sub(\" \\\\[\\D.*?\\\\]\", \"\", line)\n",
    "        strip_text.append(new)\n",
    "    strip_text = \"\\n\".join(strip_text)\n",
    "    file_df.loc[i, \"strip_text\"] = strip_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generate all stripped and cleaned text into Box folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_transcripts_dir = base_prefix + 'cleaned_data/cleaned_transcripts/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(file_df.shape[0]):\n",
    "    document = docx.Document()\n",
    "    document.add_paragraph(file_df.iloc[i][\"strip_text\"]) \n",
    "    document.save(cleaned_transcripts_dir + file_df.iloc[i][\"file_id\"] + \" final analyses.docx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert docx file to csv file\n",
    "In this section, we convert the documents to csv files by using Pandas. In the current section, we will show individual steps so that in the case that any particular file fails, we can use this section to investigate the reason and if necessary adapt this to the larger final operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Make a list having all docx files' path\n",
    "First, we are going to get the path of documnet files we want to convert to csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = glob.glob(cleaned_transcripts_dir + '*.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/p_dsi/wise/data/cleaned_data/cleaned_transcripts/129-1-198 final analyses.docx',\n",
       " '/data/p_dsi/wise/data/cleaned_data/cleaned_transcripts/088-3-198 final analyses.docx',\n",
       " '/data/p_dsi/wise/data/cleaned_data/cleaned_transcripts/273-2-198 final analyses.docx',\n",
       " '/data/p_dsi/wise/data/cleaned_data/cleaned_transcripts/107-1-198 final analyses.docx',\n",
       " '/data/p_dsi/wise/data/cleaned_data/cleaned_transcripts/116-1-198 final analyses.docx']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create \"docx_to_df\" function converting a docx file to a dataframe\n",
    "The following function operates two primary tasks. \n",
    "1. Convert a docx file to dataframe of which row is one line.\n",
    "2. Add 4 new columns [\"transcript_filepath\", \"id\", \"transcriber_id\", \"wave_filepath\"].\n",
    "\n",
    "Since the values of new columns are related to file path, I added the tasks in this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def docx_to_df(file_path):    \n",
    "    \"\"\"\n",
    "    Convert docx file to dataframe\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        A file path of documnet\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        speech | transcript_filepath | id  | transcriber_id | wave_filepath\n",
    "        ------------------------------------------------------------------\n",
    "        00:00  | Users/Soyeon/~~~.   |119-2| 113.           | Users/~~~~\n",
    "        \n",
    "    \"\"\"\n",
    "    # Convert docx file to dataframe\n",
    "    text = docx2txt.process(file_path)\n",
    "    text_list = text.split('\\n')\n",
    "    df = pd.DataFrame(text_list, columns = [\"speech\"])\n",
    "\n",
    "    # Add [transcript_filepath] column\n",
    "    df[\"transcript_filepath\"] = file_path\n",
    "\n",
    "    # Add [id], [transcriber_id] columns\n",
    "    extract = re.search('(\\d{3})-(\\d{1})-(\\d{3})', file_path)\n",
    "    if extract is not None:\n",
    "        df[\"id\"] = extract.group(1) + \"-\" + extract.group(2)\n",
    "        df[\"transcriber_id\"] = extract.group(3)\n",
    "    else:\n",
    "        df[\"id\"] = None\n",
    "        df[\"transcriber_id\"] = None\n",
    "        warnings.warn('File {0} seems to have the wrong title format for extracting id and transcriber_id'.format(file_path));\n",
    "\n",
    "    # Add [wave_filepath] column\n",
    "    audio_path = base_prefix + \"Audio Files & Transcripts/Audio Files/\"\n",
    "    df[\"wave_filepath\"] = audio_path + df[\"id\"] + \".wav\"\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Merge all dataframes\n",
    "By using list comprehension, we are going to make a list having all datafrmaes converted from docx files with the \"docx_to_df\" function. And then, we are going to create a megadata, the result from merging all the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list having all dataframes converted from the docx files\n",
    "dfs_list = [docx_to_df(file) for file in file_names]\n",
    "megadata = pd.concat(dfs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>transcript_filepath</th>\n",
       "      <th>id</th>\n",
       "      <th>transcriber_id</th>\n",
       "      <th>wave_filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- 00:00:00.00</td>\n",
       "      <td>/data/p_dsi/wise/data/cleaned_data/cleaned_tra...</td>\n",
       "      <td>129-1</td>\n",
       "      <td>198</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>can you do it really quickly. {NEU}</td>\n",
       "      <td>/data/p_dsi/wise/data/cleaned_data/cleaned_tra...</td>\n",
       "      <td>129-1</td>\n",
       "      <td>198</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just stick it in your cubby really quick pleas...</td>\n",
       "      <td>/data/p_dsi/wise/data/cleaned_data/cleaned_tra...</td>\n",
       "      <td>129-1</td>\n",
       "      <td>198</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thank you. {NEU}</td>\n",
       "      <td>/data/p_dsi/wise/data/cleaned_data/cleaned_tra...</td>\n",
       "      <td>129-1</td>\n",
       "      <td>198</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(okay) so we are going to &gt; {NEU}</td>\n",
       "      <td>/data/p_dsi/wise/data/cleaned_data/cleaned_tra...</td>\n",
       "      <td>129-1</td>\n",
       "      <td>198</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Transcript...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              speech  \\\n",
       "0                                      - 00:00:00.00   \n",
       "1                can you do it really quickly. {NEU}   \n",
       "2  just stick it in your cubby really quick pleas...   \n",
       "3                                   thank you. {NEU}   \n",
       "4                  (okay) so we are going to > {NEU}   \n",
       "\n",
       "                                 transcript_filepath     id transcriber_id  \\\n",
       "0  /data/p_dsi/wise/data/cleaned_data/cleaned_tra...  129-1            198   \n",
       "1  /data/p_dsi/wise/data/cleaned_data/cleaned_tra...  129-1            198   \n",
       "2  /data/p_dsi/wise/data/cleaned_data/cleaned_tra...  129-1            198   \n",
       "3  /data/p_dsi/wise/data/cleaned_data/cleaned_tra...  129-1            198   \n",
       "4  /data/p_dsi/wise/data/cleaned_data/cleaned_tra...  129-1            198   \n",
       "\n",
       "                                       wave_filepath  \n",
       "0  /data/p_dsi/wise/data/Audio Files & Transcript...  \n",
       "1  /data/p_dsi/wise/data/Audio Files & Transcript...  \n",
       "2  /data/p_dsi/wise/data/Audio Files & Transcript...  \n",
       "3  /data/p_dsi/wise/data/Audio Files & Transcript...  \n",
       "4  /data/p_dsi/wise/data/Audio Files & Transcript...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create \"find_timestamp\" function finding timestamp lines\n",
    "The ts_v_speech function makes a column called \"digit\". A speech line is saved as 0, and timestamp line is saved as 1 in the digit list. Secondly, it changes the format of timestamp. For example, it changes '- 00:00:00.00' into '00:00:00.00'. This timestamp is identified via regex (to be checked for formatting in the future) and also saved into the start_timestamp column.\n",
    "\n",
    "* every line starting with '-' or '[' : timestamp (1)\n",
    "* anything else: speech (0)\n",
    "\n",
    "For example, ['00:00:00.00', 'Hi', 'What is your name?', '00:03:12.00'] generates -> [1, 0, 0, 1] in the digit column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def find_timestamp(text_list):\n",
    "    \"\"\"\n",
    "    Find timestamp line and put digit's value\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text_list : dataframe\n",
    "        A dataframe you want to convert\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        it has new columns [\"start_timestamp\", \"digit\"]\n",
    "        The digit column helps filling start_timestamp and end_timestamp\n",
    "    \"\"\"\n",
    "    pat = re.compile('(\\d\\d:\\d\\d:\\d\\d. *\\d\\d)')\n",
    "    matches = pat.search(text_list['speech'])\n",
    "    if matches is not None:\n",
    "        text_list['start_timestamp'] = matches.group(1) if matches is not None else None\n",
    "        text_list['digit'] = 1\n",
    "    else:\n",
    "        text_list['digit'] = 0\n",
    "        text_list['start_timestamp'] = None\n",
    "\n",
    "    return(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "megadata = megadata.apply(find_timestamp, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Fill \"start_timestamp\" and \"end_timestamp\"\n",
    "In looking at the structure above, we can see that the ending time stamp of an utterance section is the same as the start timestamp, except shifted up one row (e.g., the start of the beginning of one series of utterances is the end of the one that came before it. We perform this programmatically.\n",
    "\n",
    "Then, we fill all of the None values with the beginning timestamp of the series of utterances (by filling non-NA values forward until they reach the next non-NA value and repeat), and then backfill the end timestamp similarly.\n",
    "\n",
    "Finally, we remove the rows of speech that are just timestamps. These are indicated by where digit==1, meaning we keep everywhere that digit==0. And then we drop this column since it has served its purpose.\n",
    "\n",
    "Some timestamp has unnecessary space in the value. So let's remove the space as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary space in start_timestamp\n",
    "megadata['start_timestamp'] = megadata['start_timestamp'].str.replace(' ', '')\n",
    "\n",
    "# Create a column \"end_timestamp\"\n",
    "megadata['end_timestamp'] = megadata['start_timestamp'].shift(-1)\n",
    "\n",
    "# Fill NA data in \"start_timestamp\" and \"end_timestamp\" columns\n",
    "megadata['start_timestamp'].ffill(inplace=True)\n",
    "megadata['end_timestamp'].bfill(inplace=True)\n",
    "\n",
    "# Remove rows of which \"speech\" is timestamp\n",
    "megadata = megadata.loc[megadata['digit']==0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>digit</th>\n",
       "      <th>id</th>\n",
       "      <th>speech</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>transcriber_id</th>\n",
       "      <th>transcript_filepath</th>\n",
       "      <th>wave_filepath</th>\n",
       "      <th>end_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>129-1</td>\n",
       "      <td>can you do it really quickly. {NEU}</td>\n",
       "      <td>00:00:00.00</td>\n",
       "      <td>198</td>\n",
       "      <td>/data/p_dsi/wise/data/cleaned_data/cleaned_tra...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Transcript...</td>\n",
       "      <td>00:02:02.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>129-1</td>\n",
       "      <td>just stick it in your cubby really quick pleas...</td>\n",
       "      <td>00:00:00.00</td>\n",
       "      <td>198</td>\n",
       "      <td>/data/p_dsi/wise/data/cleaned_data/cleaned_tra...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Transcript...</td>\n",
       "      <td>00:02:02.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>129-1</td>\n",
       "      <td>thank you. {NEU}</td>\n",
       "      <td>00:00:00.00</td>\n",
       "      <td>198</td>\n",
       "      <td>/data/p_dsi/wise/data/cleaned_data/cleaned_tra...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Transcript...</td>\n",
       "      <td>00:02:02.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>129-1</td>\n",
       "      <td>(okay) so we are going to &gt; {NEU}</td>\n",
       "      <td>00:00:00.00</td>\n",
       "      <td>198</td>\n",
       "      <td>/data/p_dsi/wise/data/cleaned_data/cleaned_tra...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Transcript...</td>\n",
       "      <td>00:02:02.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>129-1</td>\n",
       "      <td>you're gonna do the same thing name. {NEU}</td>\n",
       "      <td>00:00:00.00</td>\n",
       "      <td>198</td>\n",
       "      <td>/data/p_dsi/wise/data/cleaned_data/cleaned_tra...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Transcript...</td>\n",
       "      <td>00:02:02.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   digit     id                                             speech  \\\n",
       "1      0  129-1                can you do it really quickly. {NEU}   \n",
       "2      0  129-1  just stick it in your cubby really quick pleas...   \n",
       "3      0  129-1                                   thank you. {NEU}   \n",
       "4      0  129-1                  (okay) so we are going to > {NEU}   \n",
       "5      0  129-1         you're gonna do the same thing name. {NEU}   \n",
       "\n",
       "  start_timestamp transcriber_id  \\\n",
       "1     00:00:00.00            198   \n",
       "2     00:00:00.00            198   \n",
       "3     00:00:00.00            198   \n",
       "4     00:00:00.00            198   \n",
       "5     00:00:00.00            198   \n",
       "\n",
       "                                 transcript_filepath  \\\n",
       "1  /data/p_dsi/wise/data/cleaned_data/cleaned_tra...   \n",
       "2  /data/p_dsi/wise/data/cleaned_data/cleaned_tra...   \n",
       "3  /data/p_dsi/wise/data/cleaned_data/cleaned_tra...   \n",
       "4  /data/p_dsi/wise/data/cleaned_data/cleaned_tra...   \n",
       "5  /data/p_dsi/wise/data/cleaned_data/cleaned_tra...   \n",
       "\n",
       "                                       wave_filepath end_timestamp  \n",
       "1  /data/p_dsi/wise/data/Audio Files & Transcript...   00:02:02.12  \n",
       "2  /data/p_dsi/wise/data/Audio Files & Transcript...   00:02:02.12  \n",
       "3  /data/p_dsi/wise/data/Audio Files & Transcript...   00:02:02.12  \n",
       "4  /data/p_dsi/wise/data/Audio Files & Transcript...   00:02:02.12  \n",
       "5  /data/p_dsi/wise/data/Audio Files & Transcript...   00:02:02.12  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check result\n",
    "megadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create \"label\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We distinguish a speech line with label and without label using a regex, and saves this label into the label column. Then, it divides the speech line into actual speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pat = re.compile('.*\\{([A-Z]{3,3})\\}.*')\n",
    "megadata['label'] = megadata['speech'].apply(lambda x: None if label_pat.match(x) is None else label_pat.match(x).group(1))\n",
    "megadata['speech'] = megadata['speech'].str.replace('\\{[A-Z]{3,3}\\}', '', regex=True)\n",
    "\n",
    "# Remove unnecessary space in label and speech\n",
    "megadata.label = megadata.label.str.strip()\n",
    "megadata.speech = megadata.speech.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Clean megadata\n",
    "We remove the \"digit\" column and reorder the sequence of columns. In addtion, there are some rows having no labels. We removes this rows as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "megadata = megadata.drop('digit', axis=1)\n",
    "megadata = megadata[[\"id\", \"transcript_filepath\", \"wave_filepath\", \"speech\", 'start_timestamp', 'end_timestamp', \"label\", \"transcriber_id\"]]\n",
    "\n",
    "# Remove rows having NA values.\n",
    "megadata = megadata.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>transcript_filepath</th>\n",
       "      <th>wave_filepath</th>\n",
       "      <th>speech</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>end_timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>transcriber_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129-1</td>\n",
       "      <td>/data/p_dsi/wise/data/cleaned_data/cleaned_tra...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Transcript...</td>\n",
       "      <td>can you do it really quickly.</td>\n",
       "      <td>00:00:00.00</td>\n",
       "      <td>00:02:02.12</td>\n",
       "      <td>NEU</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129-1</td>\n",
       "      <td>/data/p_dsi/wise/data/cleaned_data/cleaned_tra...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Transcript...</td>\n",
       "      <td>just stick it in your cubby really quick pleas...</td>\n",
       "      <td>00:00:00.00</td>\n",
       "      <td>00:02:02.12</td>\n",
       "      <td>NEU</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129-1</td>\n",
       "      <td>/data/p_dsi/wise/data/cleaned_data/cleaned_tra...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Transcript...</td>\n",
       "      <td>thank you.</td>\n",
       "      <td>00:00:00.00</td>\n",
       "      <td>00:02:02.12</td>\n",
       "      <td>NEU</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129-1</td>\n",
       "      <td>/data/p_dsi/wise/data/cleaned_data/cleaned_tra...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Transcript...</td>\n",
       "      <td>(okay) so we are going to &gt;</td>\n",
       "      <td>00:00:00.00</td>\n",
       "      <td>00:02:02.12</td>\n",
       "      <td>NEU</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>129-1</td>\n",
       "      <td>/data/p_dsi/wise/data/cleaned_data/cleaned_tra...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Transcript...</td>\n",
       "      <td>you're gonna do the same thing name.</td>\n",
       "      <td>00:00:00.00</td>\n",
       "      <td>00:02:02.12</td>\n",
       "      <td>NEU</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                transcript_filepath  \\\n",
       "1  129-1  /data/p_dsi/wise/data/cleaned_data/cleaned_tra...   \n",
       "2  129-1  /data/p_dsi/wise/data/cleaned_data/cleaned_tra...   \n",
       "3  129-1  /data/p_dsi/wise/data/cleaned_data/cleaned_tra...   \n",
       "4  129-1  /data/p_dsi/wise/data/cleaned_data/cleaned_tra...   \n",
       "5  129-1  /data/p_dsi/wise/data/cleaned_data/cleaned_tra...   \n",
       "\n",
       "                                       wave_filepath  \\\n",
       "1  /data/p_dsi/wise/data/Audio Files & Transcript...   \n",
       "2  /data/p_dsi/wise/data/Audio Files & Transcript...   \n",
       "3  /data/p_dsi/wise/data/Audio Files & Transcript...   \n",
       "4  /data/p_dsi/wise/data/Audio Files & Transcript...   \n",
       "5  /data/p_dsi/wise/data/Audio Files & Transcript...   \n",
       "\n",
       "                                              speech start_timestamp  \\\n",
       "1                      can you do it really quickly.     00:00:00.00   \n",
       "2  just stick it in your cubby really quick pleas...     00:00:00.00   \n",
       "3                                         thank you.     00:00:00.00   \n",
       "4                        (okay) so we are going to >     00:00:00.00   \n",
       "5               you're gonna do the same thing name.     00:00:00.00   \n",
       "\n",
       "  end_timestamp label transcriber_id  \n",
       "1   00:02:02.12   NEU            198  \n",
       "2   00:02:02.12   NEU            198  \n",
       "3   00:02:02.12   NEU            198  \n",
       "4   00:02:02.12   NEU            198  \n",
       "5   00:02:02.12   NEU            198  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>transcript_filepath</th>\n",
       "      <th>wave_filepath</th>\n",
       "      <th>speech</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>end_timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>transcriber_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>088-1</td>\n",
       "      <td>/data/p_dsi/wise/data/cleaned_data/cleaned_tra...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Transcript...</td>\n",
       "      <td>you know what he did get really big and turn i...</td>\n",
       "      <td>00:00:00.00</td>\n",
       "      <td>00:02:05.18</td>\n",
       "      <td>OTR</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>088-1</td>\n",
       "      <td>/data/p_dsi/wise/data/cleaned_data/cleaned_tra...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Transcript...</td>\n",
       "      <td>he was small when he came out of the egg.</td>\n",
       "      <td>00:00:00.00</td>\n",
       "      <td>00:02:05.18</td>\n",
       "      <td>NEU</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>088-1</td>\n",
       "      <td>/data/p_dsi/wise/data/cleaned_data/cleaned_tra...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Transcript...</td>\n",
       "      <td>remember name.</td>\n",
       "      <td>00:00:00.00</td>\n",
       "      <td>00:02:05.18</td>\n",
       "      <td>NEU</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>088-1</td>\n",
       "      <td>/data/p_dsi/wise/data/cleaned_data/cleaned_tra...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Transcript...</td>\n",
       "      <td>and how did he get to be so big name.</td>\n",
       "      <td>00:00:00.00</td>\n",
       "      <td>00:02:05.18</td>\n",
       "      <td>OTR</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>088-1</td>\n",
       "      <td>/data/p_dsi/wise/data/cleaned_data/cleaned_tra...</td>\n",
       "      <td>/data/p_dsi/wise/data/Audio Files &amp; Transcript...</td>\n",
       "      <td>what did he do?</td>\n",
       "      <td>00:00:00.00</td>\n",
       "      <td>00:02:05.18</td>\n",
       "      <td>OTR</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                transcript_filepath  \\\n",
       "156  088-1  /data/p_dsi/wise/data/cleaned_data/cleaned_tra...   \n",
       "157  088-1  /data/p_dsi/wise/data/cleaned_data/cleaned_tra...   \n",
       "158  088-1  /data/p_dsi/wise/data/cleaned_data/cleaned_tra...   \n",
       "159  088-1  /data/p_dsi/wise/data/cleaned_data/cleaned_tra...   \n",
       "160  088-1  /data/p_dsi/wise/data/cleaned_data/cleaned_tra...   \n",
       "\n",
       "                                         wave_filepath  \\\n",
       "156  /data/p_dsi/wise/data/Audio Files & Transcript...   \n",
       "157  /data/p_dsi/wise/data/Audio Files & Transcript...   \n",
       "158  /data/p_dsi/wise/data/Audio Files & Transcript...   \n",
       "159  /data/p_dsi/wise/data/Audio Files & Transcript...   \n",
       "160  /data/p_dsi/wise/data/Audio Files & Transcript...   \n",
       "\n",
       "                                                speech start_timestamp  \\\n",
       "156  you know what he did get really big and turn i...     00:00:00.00   \n",
       "157          he was small when he came out of the egg.     00:00:00.00   \n",
       "158                                     remember name.     00:00:00.00   \n",
       "159              and how did he get to be so big name.     00:00:00.00   \n",
       "160                                    what did he do?     00:00:00.00   \n",
       "\n",
       "    end_timestamp label transcriber_id  \n",
       "156   00:02:05.18   OTR            198  \n",
       "157   00:02:05.18   NEU            198  \n",
       "158   00:02:05.18   NEU            198  \n",
       "159   00:02:05.18   OTR            198  \n",
       "160   00:02:05.18   OTR            198  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megadata.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this looks great! Now, let's save this dataframe as csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Save dataframe as csv files\n",
    "We are done! Let's save this as a csv file. There are two options here:\n",
    "1. Save the megadata(having all documents' data) as a csv file.\n",
    "2. Group megadata by id and create different csv file.\n",
    "\n",
    "If you want to run the code to create new csv files, please remove \"#\" in front of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_filepath = base_prefix + \"cleaned_data/csv_files/\"\n",
    "\n",
    "# (Option #1)Save the megadata as one csv file \n",
    "#megadata.to_csv(new_filepath + \"megadata.csv\", index = False)\n",
    "\n",
    "# (Option #2)Save dataframe grouped by id as a csv file\n",
    "id_list = megadata[\"id\"].unique()\n",
    "megadata_groupby_id = megadata.groupby('id')\n",
    "for i in id_list:\n",
    "    df = megadata_groupby_id.get_group(i)\n",
    "#    df.to_csv(new_filepath + i + \".csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
