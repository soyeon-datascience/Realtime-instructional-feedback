# AUTOGENERATED! DO NOT EDIT! File to edit: 10-process-data.ipynb (unless otherwise specified).

__all__ = ['getText', 'docx_to_df', 'find_timestamp', 'add_splits', 'check_label', 'check_ts']

# Cell
# data access and processing
import pandas as pd
import numpy as np

# File helpers
import glob

# python helpers
import os.path
import re
import warnings

# docx helpers
import docx
import docx2txt

# Cell
def getText(filename):
    """
    Import document file and show in python environment

    Parmeters
    ---------
    filename : str
        a document's file path

    Returns
    -------
    str
        the document's contents
    """
    doc = docx.Document(filename)
    fullText = []
    for para in doc.paragraphs:
        fullText.append(para.text)
    return '\n'.join(fullText)

# Cell
def docx_to_df(file_path):
    """
    Convert docx file to dataframe

    Parameters
    ----------
    file_path : str
        A file path of documnet

    Returns
    -------
    dataframe
        speech | transcript_filepath | id  | transcriber_id | wave_filepath
        ------------------------------------------------------------------
        00:00  | Users/Soyeon/~~~.   |119-2| 113.           | Users/~~~~

    """
    # Convert docx file to dataframe
    text = docx2txt.process(file_path)
    text_list = text.split('\n')
    df = pd.DataFrame(text_list, columns = ["speech"])

    # Add [transcript_filepath] column
    df["transcript_filepath"] = file_path

    # Add [id], [transcriber_id] columns
    extract = re.search('(\d{3})-(\d{1})-(\d{3})', file_path)
    if extract is not None:
        df["id"] = extract.group(1) + "-" + extract.group(2)
        df["transcriber_id"] = extract.group(3)
    else:
        df["id"] = None
        df["transcriber_id"] = None
        warnings.warn('File {0} seems to have the wrong title format for extracting id and transcriber_id'.format(file_path));

    # Add [wave_filepath] column
    audio_path = base_prefix + "Audio Files & Transcripts/Audio Files/"
    df["wave_filepath"] = audio_path + df["id"] + ".wav"

    return df

# Cell
def find_timestamp(text_list):
    """
    Find timestamp line and put digit's value

    Parameters
    ----------
    text_list : dataframe
        A dataframe you want to convert

    Returns
    -------
    dataframe
        it has new columns ["start_timestamp", "digit"]
        The digit column helps filling start_timestamp and end_timestamp
    """
    pat = re.compile('(\d\d:\d\d:\d\d. *\d\d)')
    matches = pat.search(text_list['speech'])
    if matches is not None:
        text_list['start_timestamp'] = matches.group(1) if matches is not None else None
        text_list['digit'] = 1
    else:
        text_list['digit'] = 0
        text_list['start_timestamp'] = None

    return(text_list)

# Comes from 12-training-dev-test.ipynb, cell
#data access and processing
import pandas as pd
import numpy as np

#splitting the data
from sklearn.model_selection import StratifiedShuffleSplit

#python and file system operations
import glob
import os.path
import docx
import re

# Suppress all warning
import warnings
warnings.filterwarnings('ignore')

# Comes from 12-training-dev-test.ipynb, cell
def add_splits(full_df, seed = 0, test_ratio = 0.1, dev_ratio = 0.1):
    '''
    This function takes in a Pandas DataFrame and returns a new pandas data frame which uses StratifiedShuffleSplit functions to split them
    in accordance with the same distribution of the complete set
    train split = 0
    validation split = 1
    test split = 2

    Argument:
    data_name: data file name
    seed: control reproducible splits
    test_ratio: percentage of test set of the original complete data
    dev_ratio: percentage of validation set of the original complete data
    '''

    # Drop NA to make sure StratifiedSplit function can run it
    df = full_df[full_df['label'].notna()]

    # Correct typo labels
    df['label'][df['label'] == "NO"] = "NEU"
    df['label'][df['label'] == "NUE"] = "NEU"
    df['label'][df['label'] == "OT"] = "OTR"
    df['label'][df['label'] == "OTS"] = "OTR"

    # We get 10% test set now and 90% training set
    sss = StratifiedShuffleSplit(n_splits = 1, test_size = test_ratio, random_state= seed)

    # Split them into training and test set
    for train_index, test_index in sss.split(np.zeros(df.shape[0]), df['label'].to_numpy()):
        df_train = df.iloc[train_index]
        df_test = df.iloc[test_index]

    # We divide by 1/9 percentage of current new training set to get 10% validation set of the original whole dataset
    sss = StratifiedShuffleSplit(n_splits = 1, test_size = dev_ratio / (1 - test_ratio), random_state= seed)

    # Split them into final traning and validation set
    for train_index, dev_index in sss.split(np.zeros(df_train.shape[0]), df_train['label'].to_numpy()):
        df_train = df.iloc[train_index]
        df_dev = df.iloc[dev_index]

    # Add a split column, use train = 0, validation = 1, test = 2
    df_train["split"] = 0
    df_dev["split"] = 1
    df_test["split"] = 2

    # Row bind all dataframe
    df_train_dev_test = pd.concat([df_train, df_dev, df_test])

    # Print each dataset size
    print("Train size is: " + str((1-test_ratio-dev_ratio)*100) + "%,", df_train.shape[0])
    print("Validation size is: " + str((dev_ratio)*100) + "%," ,df_dev.shape[0])
    print("Test size is: " + str((test_ratio)*100) + "%,", df_test.shape[0])

    return df_train_dev_test

# Comes from 13-validate-csv.ipynb, cell
import pandas as pd
import re
import os.path

# Comes from 13-validate-csv.ipynb, cell
def check_label(dataframe, accepted_labels = None):
    """
    Validate labels

    Parameters
    ----------
    dataframe : dataframe
        a dataframe that you want to check labels
    accepted_labels: either None or a list of new labels
        None: When you want to use the default labels ('PRS', 'REP', 'OTR', 'NEU')
        a list of new labels: When you want to change the labels (ex. ['OTR_academic, 'OTR_behavior])

    Returns
    -------
    dataframe
        rows of which label is not an element of the list we input
    """
    if accepted_labels == None:
        label_list = ['PRS', 'REP', 'OTR', 'NEU']
        return dataframe[~dataframe['label'].isin(label_list)]
    else:
        label_list = accepted_labels
        return dataframe[~dataframe['label'].isin(label_list)]

# Comes from 13-validate-csv.ipynb, cell
def check_ts(dataframe, outfile_name = 'megadata_final', interactive=False):
    """
    Find start/end_timestamp in wrong format
    If an user wants to change the wrong start_timestamp and end_timestamp, he/she can change it and save it.

    Parameters
    ----------
    dataframe: dataframe
        A dataframe you want to validate in terms of start_timestamp and end_timestamp
    outfile_name: string (default 'megadata_final')
        String of the filename you want the new file saved to
    interactive: boolean (default False)
        Determines whether you want to interactively change the values or just see the errors.

    Returns
    -------
    dataframe
        Rows having start/end_timestamp in wrong format
        It also asks users if he/she wants to change the wrong timestamp.
        If the user wants to change it, he/she can type a correct timestamp and save it.
    """
    # Find the rows having start/end_timestamp in wrong format
    df_ts_typo = dataframe[(~dataframe.start_timestamp.str.match('\d\d:\d\d:\d\d\.\d\d')) | (~dataframe.end_timestamp.str.match('\d\d:\d\d:\d\d\.\d\d'))]
    display(df_ts_typo)

    # Get the list of timestamp in wrong format
    df_start_ts_typo = dataframe[(~dataframe.start_timestamp.str.match('\d\d:\d\d:\d\d\.\d\d'))]
    df_end_ts_typo = dataframe[(~dataframe.end_timestamp.str.match('\d\d:\d\d:\d\d\.\d\d'))]
    total_typos = len(df_start_ts_typo) + len(df_end_ts_typo)

    # Get unique timestamps
    start_ts_list = df_start_ts_typo['start_timestamp'].unique().tolist()
    end_ts_list = df_end_ts_typo['end_timestamp'].unique().tolist()
    combine = start_ts_list + end_ts_list
    combine = list(set(combine))

    # Show the number of timestamp in wrong format
    print('There are', len(combine), 'unique timestamps in wrong format with a total of', total_typos, 'incorrect rows.')

    if interactive:

        # Check all the timestamp in incorrect format
        for i in combine:
            user_answer1 = input("Do you want to change {}? y/n \n".format(i))
            if user_answer1 == "y":
                user_answer2 = input("What is the correct value?\n")
                dataframe.loc[dataframe.start_timestamp == i, 'start_timestamp'] = user_answer2
                dataframe.loc[dataframe.end_timestamp == i, 'end_timestamp'] = user_answer2
                print("The new value has been updated.")
            else:
                print("Please go to the original docx file and correct it.")

        # Ask a user if he/she wants to save the change
        user_answer3 = input("Do you want to save the changes? y/n \n")
        if user_answer3 == "y":
            output_filepath = base_prefix + 'cleaned_data/csv_files/' + outfile_name + '.csv'
            dataframe.to_csv(output_filepath, index=False)
            print("You just saved your updated changes. The updated file is: ", output_filepath, '.')
        else:
            print("You did not save the change.")

    return