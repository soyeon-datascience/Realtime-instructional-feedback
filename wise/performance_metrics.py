# AUTOGENERATED! DO NOT EDIT! File to edit: 90-general-metrics-evaluation.ipynb (unless otherwise specified).

__all__ = ['zsresults_to_df', 'get_performance_metrics']

# Cell
#Data analysis and processing
import pandas as pd

#Plotting functions
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

# Cell
def zsresults_to_df(csv_df, zeroshot_results, labels_rename):
    '''
    Function zsresults_to_df: Converts HF zero-shot pipeline outputs to a dataframe
    Inputs: csv_df: pandas dataframe with continuous index and at least columns label and speech
            zeroshot_results: output of HF zeroshot classification (list of dictionaries)
            labels_rename: dictionary with keys corresponding to labels in the data and values corresponding
                to zero-shot label "nicknames" (e.g., one element would be 'PRS':'praise')
    Returns: a dataframe of the results, with new columns 'pred_zslabels' - pipeline predictions as "nicknames",
            'pred' - pipeline predictions as the original data labels
            'truth' - ground truth from csv_df
            'sequence' - csv_df 'speech' column used for checking correctness of merge
            columns corresponding to each "nickname" label filled with pipeline inference probabilities.
            Each row is 1:1 with csv_df.
    '''

    #Separate out the labels given in the data vs the zeroshot nicknames we gave them
    data_labels, label_nicknames = [list(el) for el in zip(*labels_rename.items())]
    nicknames_to_labels = dict(zip(label_nicknames, data_labels))

    #Parse through zeroshot_results to make a list of dataframes
    results_df_list = [pd.DataFrame(result) for result in zeroshot_results]

    #Add back original indices to make sure concatenation works correctly
    csv_df = csv_df.reset_index().rename(columns={'index':'sample_id'})
    results_df_list = [df.assign(sample_id = ind) for ind, df in enumerate(results_df_list)]

    #Concatenate all dataframes the list into a single dataframe
    results_df = pd.concat(results_df_list)

    #Pivot the column of labels and probabilities to be a single row per sample (long to wide)
    results_df = results_df.pivot(index=['sample_id', 'sequence'], columns='labels', values='scores').reset_index(level='sequence')
    results_df['pred_zslabels'] = results_df[label_nicknames].idxmax(axis=1)

    #Substitute zero-shot names with real (in the data) label names
    results_df['pred'] = results_df['pred_zslabels'].replace(nicknames_to_labels)

    #Merge results table with original csv to get original labels
    results_df = results_df.merge(csv_df[['sample_id', 'label', 'speech']], left_index=True, right_on='sample_id')

    #Fix label weirdness (remove unwanted spaces in labels)
    results_df['label'] = results_df['label'].str.strip()

    #Specify the true label as "truth"
    results_df = results_df.rename(columns={'label':'truth'})

    return results_df

# Cell
def get_performance_metrics(truth_vec, preds_vec, labels_rename, show_plots=False):
    '''
    Function get_performance_metrics: Returns performance metrics for classification
    Inputs: truth_vec: pandas series or numpy array corresponding with ground truth "data" labels
            preds_vec: pandas series or numpy array corresponding to the predicted "data" labels
            labels_rename: dictionary of "data labels":nicknames (e.g., {'PRS':'praise'}) or
                           list of true labels (e.g., ['PRS', 'REP'])
            show_plots (default False): if True, shows pretty confusion matrix and classification report
    Returns: dataframe of confusion matrix, dataframe of classification report
    '''

    #determine type of labels_rename_lookup to determine action
    #this allows us to use the same function for zero-shot classification and regular classification
    if isinstance(labels_rename, list):
        labels_rename = dict(zip(labels_rename, labels_rename))

    #get the different elements
    data_labels, label_nicknames = [list(el) for el in zip(*labels_rename.items())]

    #Create confusion matrix using sklearn
    c_ma = confusion_matrix(truth_vec, preds_vec, labels=data_labels)

    #Create confusion matrix as dataframe
    c_df = pd.DataFrame(c_ma,
                        columns = data_labels,
                        index = data_labels)
    c_df.rename(columns=labels_rename, index=labels_rename, inplace=True)
    c_df.index.name = 'Actual Labels'
    c_df.columns.name = 'Predicted Labels'

    #Get classification report as dataframe
    perf_metrics = classification_report(truth_vec, preds_vec,
                                         labels=data_labels, target_names = label_nicknames,
                                         output_dict=True)
    perf_metrics = pd.DataFrame(perf_metrics)

    #Show formatted confusion matrix
    if show_plots:
        print('Classification Report:')
        ax = sns.heatmap(c_df, cmap='Blues', annot=True, fmt='d');
        ax.set_xticklabels(ax.get_xticklabels(),rotation = 45);
        ax.set_yticklabels(ax.get_yticklabels(),rotation = 45);
        ax.set_title('Confusion Matrix')
        print(classification_report(truth_vec, preds_vec, labels=data_labels, target_names = label_nicknames))

    return c_df, perf_metrics