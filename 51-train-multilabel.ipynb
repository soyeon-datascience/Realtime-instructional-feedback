{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47c6d217",
   "metadata": {},
   "source": [
    "# 51-train-multilabel\n",
    "> An exploration of training for multilabel classification on the audio model\n",
    "\n",
    "In this notebook, we continue using wav2vec2, except now we extend this to using multilabel classification. The model trained here is trained on equal lengths of audio, and all labels occuring in that segment are attributed to the that segment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d02413",
   "metadata": {},
   "source": [
    "### Read in packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b797f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_no_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecc0296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modeling imports\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForSequenceClassification, pipeline, TrainingArguments, Trainer\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import librosa\n",
    "\n",
    "#ds imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "#python imports\n",
    "import os.path\n",
    "import glob\n",
    "import re\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555f4c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "sampling_rate = 16000\n",
    "base_prefix = '/data/p_dsi/wise/data/'\n",
    "test_audio_id = '055-1'\n",
    "sample_csv_dir = base_prefix + 'multilabel_parquet/'\n",
    "audio_dir = base_prefix + 'resampled_audio_16khz/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e66e59",
   "metadata": {},
   "source": [
    "# Read in audio and encoding data\n",
    "We read in the subsegmented data generated in another notebook and stored as a parquet file. We also read in an audio file to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830dc974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>speech_list</th>\n",
       "      <th>speech</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>end_timestamp</th>\n",
       "      <th>start_ms</th>\n",
       "      <th>end_ms</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>start_index</th>\n",
       "      <th>end_index</th>\n",
       "      <th>OTR</th>\n",
       "      <th>NEU</th>\n",
       "      <th>REP</th>\n",
       "      <th>PRS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>055-1</td>\n",
       "      <td>[(okay) we are gonna go on and get started guys.]</td>\n",
       "      <td>(okay) we are gonna go on and get started guys.</td>\n",
       "      <td>[NEU]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>00:01.000</td>\n",
       "      <td>00:03.380</td>\n",
       "      <td>1000</td>\n",
       "      <td>3380</td>\n",
       "      <td>2380</td>\n",
       "      <td>16000</td>\n",
       "      <td>54080</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>055-1</td>\n",
       "      <td>[we are gonna do a little bit of reviewing wit...</td>\n",
       "      <td>we are gonna do a little bit of reviewing with...</td>\n",
       "      <td>[NEU]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>00:03.750</td>\n",
       "      <td>00:06.763</td>\n",
       "      <td>3750</td>\n",
       "      <td>6763</td>\n",
       "      <td>3013</td>\n",
       "      <td>60000</td>\n",
       "      <td>108208</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>055-1</td>\n",
       "      <td>[(now) keep in mind that we are playing the go...</td>\n",
       "      <td>(now) keep in mind that we are playing the goo...</td>\n",
       "      <td>[NEU]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>00:07.150</td>\n",
       "      <td>00:12.769</td>\n",
       "      <td>7150</td>\n",
       "      <td>12769</td>\n",
       "      <td>5619</td>\n",
       "      <td>114400</td>\n",
       "      <td>204304</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>055-1</td>\n",
       "      <td>[everyone look up here please.]</td>\n",
       "      <td>everyone look up here please.</td>\n",
       "      <td>[NEU]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>00:14.012</td>\n",
       "      <td>00:16.260</td>\n",
       "      <td>14012</td>\n",
       "      <td>16260</td>\n",
       "      <td>2248</td>\n",
       "      <td>224192</td>\n",
       "      <td>260160</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>055-1</td>\n",
       "      <td>[let's go over the problems., most of you are ...</td>\n",
       "      <td>let's go over the problems. most of you are done.</td>\n",
       "      <td>[NEU, NEU]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>00:16.615</td>\n",
       "      <td>00:19.125</td>\n",
       "      <td>16615</td>\n",
       "      <td>19125</td>\n",
       "      <td>2510</td>\n",
       "      <td>265840</td>\n",
       "      <td>306000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>055-1</td>\n",
       "      <td>[if you are not you're just gonna follow along.]</td>\n",
       "      <td>if you are not you're just gonna follow along.</td>\n",
       "      <td>[NEU]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>00:19.125</td>\n",
       "      <td>00:21.762</td>\n",
       "      <td>19125</td>\n",
       "      <td>21762</td>\n",
       "      <td>2637</td>\n",
       "      <td>306000</td>\n",
       "      <td>348192</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>055-1</td>\n",
       "      <td>[(now) remember when we group&gt;]</td>\n",
       "      <td>(now) remember when we group&gt;</td>\n",
       "      <td>[NEU]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>00:22.375</td>\n",
       "      <td>00:24.000</td>\n",
       "      <td>22375</td>\n",
       "      <td>24000</td>\n",
       "      <td>1625</td>\n",
       "      <td>358000</td>\n",
       "      <td>384000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>055-1</td>\n",
       "      <td>[raise your hand if you can tell me what numbe...</td>\n",
       "      <td>raise your hand if you can tell me what number...</td>\n",
       "      <td>[OTR]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>00:24.010</td>\n",
       "      <td>00:32.596</td>\n",
       "      <td>24010</td>\n",
       "      <td>32595</td>\n",
       "      <td>8585</td>\n",
       "      <td>384160</td>\n",
       "      <td>521520</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>055-1</td>\n",
       "      <td>[what number name]</td>\n",
       "      <td>what number name</td>\n",
       "      <td>[OTR]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>00:33.250</td>\n",
       "      <td>00:34.697</td>\n",
       "      <td>33250</td>\n",
       "      <td>34697</td>\n",
       "      <td>1447</td>\n",
       "      <td>532000</td>\n",
       "      <td>555152</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>055-1</td>\n",
       "      <td>[okay ten or more.]</td>\n",
       "      <td>okay ten or more.</td>\n",
       "      <td>[NEU]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>00:35.250</td>\n",
       "      <td>00:37.375</td>\n",
       "      <td>35250</td>\n",
       "      <td>37375</td>\n",
       "      <td>2125</td>\n",
       "      <td>564000</td>\n",
       "      <td>598000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        speech_list  \\\n",
       "0  055-1  [(okay) we are gonna go on and get started guys.]   \n",
       "1  055-1  [we are gonna do a little bit of reviewing wit...   \n",
       "2  055-1  [(now) keep in mind that we are playing the go...   \n",
       "3  055-1                    [everyone look up here please.]   \n",
       "4  055-1  [let's go over the problems., most of you are ...   \n",
       "5  055-1   [if you are not you're just gonna follow along.]   \n",
       "6  055-1                    [(now) remember when we group>]   \n",
       "7  055-1  [raise your hand if you can tell me what numbe...   \n",
       "8  055-1                                 [what number name]   \n",
       "9  055-1                                [okay ten or more.]   \n",
       "\n",
       "                                              speech       label label_id  \\\n",
       "0    (okay) we are gonna go on and get started guys.       [NEU]      [1]   \n",
       "1  we are gonna do a little bit of reviewing with...       [NEU]      [1]   \n",
       "2  (now) keep in mind that we are playing the goo...       [NEU]      [1]   \n",
       "3                      everyone look up here please.       [NEU]      [1]   \n",
       "4  let's go over the problems. most of you are done.  [NEU, NEU]   [1, 1]   \n",
       "5     if you are not you're just gonna follow along.       [NEU]      [1]   \n",
       "6                      (now) remember when we group>       [NEU]      [1]   \n",
       "7  raise your hand if you can tell me what number...       [OTR]      [0]   \n",
       "8                                   what number name       [OTR]      [0]   \n",
       "9                                  okay ten or more.       [NEU]      [1]   \n",
       "\n",
       "  start_timestamp end_timestamp  start_ms  end_ms  duration_ms  start_index  \\\n",
       "0       00:01.000     00:03.380      1000    3380         2380        16000   \n",
       "1       00:03.750     00:06.763      3750    6763         3013        60000   \n",
       "2       00:07.150     00:12.769      7150   12769         5619       114400   \n",
       "3       00:14.012     00:16.260     14012   16260         2248       224192   \n",
       "4       00:16.615     00:19.125     16615   19125         2510       265840   \n",
       "5       00:19.125     00:21.762     19125   21762         2637       306000   \n",
       "6       00:22.375     00:24.000     22375   24000         1625       358000   \n",
       "7       00:24.010     00:32.596     24010   32595         8585       384160   \n",
       "8       00:33.250     00:34.697     33250   34697         1447       532000   \n",
       "9       00:35.250     00:37.375     35250   37375         2125       564000   \n",
       "\n",
       "   end_index  OTR  NEU  REP  PRS  \n",
       "0      54080    0    1    0    0  \n",
       "1     108208    0    1    0    0  \n",
       "2     204304    0    1    0    0  \n",
       "3     260160    0    1    0    0  \n",
       "4     306000    0    2    0    0  \n",
       "5     348192    0    1    0    0  \n",
       "6     384000    0    1    0    0  \n",
       "7     521520    1    0    0    0  \n",
       "8     555152    1    0    0    0  \n",
       "9     598000    0    1    0    0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(177, 16)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read audio data\n",
    "class_audio, class_sr = sf.read(audio_dir + test_audio_id + '.wav')\n",
    "\n",
    "#read dataframe and preview\n",
    "ts_df = pd.read_parquet(sample_csv_dir + test_audio_id + '.parquet')\n",
    "display(ts_df.head(10))\n",
    "ts_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201ed047",
   "metadata": {},
   "source": [
    "# Data pre-processing\n",
    "## Get audio clips (inputs)\n",
    "Here, we'll split up the audio data and groom the labels to be one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e07179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split audio into 20*sampling_rate equal segments\n",
    "audio_clips = [class_audio[start:end+1] for start, end in ts_df[['start_index', 'end_index']].values]\n",
    "len(audio_clips)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd2bcaf",
   "metadata": {},
   "source": [
    "## Get labels in correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459bb7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OTR': 0, 'NEU': 1, 'REP': 2, 'PRS': 3}\n",
      "{0: 'OTR', 1: 'NEU', 2: 'REP', 3: 'PRS'}\n"
     ]
    }
   ],
   "source": [
    "#create some data labels to enforce consistency of label order\n",
    "data_labels = ['OTR', 'NEU', 'REP', 'PRS']\n",
    "\n",
    "#create forward and reverse dictionaries\n",
    "label2id = {label:lid for lid, label in enumerate(data_labels)}\n",
    "id2label = {value:key for key, value in label2id.items()}\n",
    "\n",
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34193d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 0, 0],\n",
       " [0, 1, 0, 0],\n",
       " [0, 1, 0, 0],\n",
       " [0, 1, 0, 0],\n",
       " [0, 1, 0, 0],\n",
       " [0, 1, 0, 0]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n"
     ]
    }
   ],
   "source": [
    "#convert labels to one-hot encoding\n",
    "multilabels = (ts_df[data_labels]>0).astype(int)\n",
    "new_total = multilabels.values.tolist()\n",
    "\n",
    "#sanity checks\n",
    "display(new_total[:6])\n",
    "print(len(new_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60441da2",
   "metadata": {},
   "source": [
    "# Split train and test\n",
    "Here, we'll split the data to make sure we have a training and validation set. We'll need a test set as well at some point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd20f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine training size\n",
    "train_size = round(ts_df.shape[0]*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74f2201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n",
      "[-0.00299072 -0.00701904 -0.00869751 -0.00930786 -0.00946045 -0.0085144\n",
      " -0.0057373  -0.00164795 -0.00030518 -0.00048828]\n",
      "[-4.88281250e-04  3.05175781e-05  5.18798828e-04  8.23974609e-04\n",
      "  8.54492188e-04  1.12915039e-03  1.15966797e-03  8.54492188e-04\n",
      "  7.32421875e-04  9.46044922e-04]\n",
      "35\n",
      "60497\n"
     ]
    }
   ],
   "source": [
    "#split data\n",
    "audio_clips_train = audio_clips[:train_size]\n",
    "audio_clips_test = audio_clips[train_size:]\n",
    "\n",
    "#this looks about right\n",
    "print(len(audio_clips_train))\n",
    "print(audio_clips_train[0][:10])\n",
    "print(audio_clips_train[1][:10])\n",
    "print(len(audio_clips_test))\n",
    "print(len(audio_clips_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604dfd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create lists for labels\n",
    "train_label = new_total[:train_size]\n",
    "test_label = new_total[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd6626a",
   "metadata": {},
   "source": [
    "# Prepare inputs for wav2vec2\n",
    "Here, we pre-process the inputs specifically for wav2vec2 models. We also create a custom dataset which will generate the inputs as desired by the HuggingFace API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563019ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb19ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process inputs appropriately\n",
    "train_inputs = processor(audio_clips_train, return_tensors=\"pt\", padding=\"longest\", sampling_rate=sampling_rate)\n",
    "test_inputs = processor(audio_clips_test, return_tensors=\"pt\", padding=\"longest\", sampling_rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33479409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helpers for class size and class names\n",
    "no_classes = len(train_label[0])\n",
    "\n",
    "#Create custom Datasets Class\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels, is_multilabel=False):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.is_multilabel = is_multilabel\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
    "        if self.is_multilabel:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        else:\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "#Create datasets from encodings\n",
    "train_dataset = CustomDataset(train_inputs, train_label, is_multilabel=True)\n",
    "val_dataset = CustomDataset(test_inputs, test_label, is_multilabel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a7ffcb",
   "metadata": {},
   "source": [
    "# Setup model for training\n",
    "Here, we define a number of functions which will allow our model to perform multilabel classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f677b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['classifier.weight', 'projector.bias', 'wav2vec2.masked_spec_embed', 'classifier.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(\"facebook/wav2vec2-base-960h\",\n",
    "                                                          num_labels=no_classes,\n",
    "                                                          id2label=id2label,\n",
    "                                                          label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b339fc",
   "metadata": {},
   "source": [
    "This function is just to create a shorthand for try/except. It's used in the computation of ROC AUC score. On the off-chance that the AUC cannot be calculated, this unfortunately throws an error which we need to catch; if we don't, the whole `trainer.evaluate()` function fails and we cannot see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7668723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_except(try_exp):\n",
    "    '''\n",
    "    Function try_except: a helper function for streamlining try/except statements\n",
    "        Inputs: callable to be executed\n",
    "        Output: the successful output of the called input or np.nan\n",
    "    '''\n",
    "    try:\n",
    "        return try_exp()\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00baefe2",
   "metadata": {},
   "source": [
    "This function is exactly as it reads; it's a function used to compute some metrics. These metrics are shown during training on the evaluation set. For more information on the format of what a metric output should look like, see the [GitHub metrics repository](https://github.com/huggingface/datasets/blob/master/metrics/accuracy/accuracy.py) where several are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce58e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    '''\n",
    "    Function compute_metrics: computes a number of metrics and returns a dictionary as required by HF API\n",
    "        Inputs: eval_pred: output of forward pass of HF\n",
    "        Outputs: dictionary containing named metrics\n",
    "    '''\n",
    "    \n",
    "    #separate components of forward pass and labels\n",
    "    logits, labels = eval_pred\n",
    "    \n",
    "    #Calculate probabilities and get hard predictions\n",
    "    probabilities = torch.sigmoid(torch.tensor(logits))#.data\n",
    "    predictions = (probabilities>= 0.5).float()\n",
    "    \n",
    "    #Calculate metrics of interest to be returned as a dictionary\n",
    "    metrics_calculated = {'f1_score_samples_mean': f1_score(labels.astype(float), predictions, average='samples'),\n",
    "                          'f1_score_macro_mean': f1_score(labels.astype(float), predictions, average='macro'),\n",
    "                          'roc_auc_samples_mean': try_except(lambda: roc_auc_score(labels, predictions, average='samples')),\n",
    "                          'roc_auc_macro_mean': try_except(lambda: roc_auc_score(labels, predictions, average='macro'))}\n",
    "\n",
    "    return metrics_calculated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd0d174",
   "metadata": {},
   "source": [
    "The `compute_loss` function of `MultilabelTrainer` below is a bit squirrely, and with new commits to the wav2vec2 model source code (current commit is 6645eb61fa61cd24c77), I'm sure that it will become obselete. The source code of the forward pass is [here](https://github.com/huggingface/transformers/blob/master/src/transformers/models/wav2vec2/modeling_wav2vec2.py#L1716).  The problem lies on lines[1762-1764](https://github.com/huggingface/transformers/blob/master/src/transformers/models/wav2vec2/modeling_wav2vec2.py#L1762).\n",
    "\n",
    "As you can see, by default, the forward pass wants to compute CrossEntropyLoss. This doesn't work for us; however, it only runs in the case that labels is not None. So, we force labels to be None, and skip that step and use our own loss calculation. This is a bit hacky; another approach would be to inherit from wav2vec2 and then write a new forward pass. This seems...unfortunate when something small like this can be integrated in.\n",
    "\n",
    "A second part of this is that the `inputs` parameter passed in already has the `labels` parameter inside it as a key in the dictionary. So, we need to snatch that out before calling the forward pass of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff097523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subclassing trainer to customize the loss function\n",
    "class MultilabelTrainer(Trainer):\n",
    "    '''\n",
    "    Class MultilabelTrainer: Subclass of Trainer class for with loss function tailored to multilabel classification\n",
    "    '''\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        #get the labels\n",
    "        labels = inputs.get(\"labels\")\n",
    "        \n",
    "        #replace forward call for labels with None. This prevents the default loss computation from wav2vec2\n",
    "        #and get outputs\n",
    "        outputs = model(**{key:value for key,value in inputs.items() if key!='labels'}, labels=None)\n",
    "        \n",
    "        #get logits and compute loss\n",
    "        logits = outputs.get('logits')\n",
    "        loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels),\n",
    "                        labels.float().view(-1, self.model.config.num_labels))\n",
    "        \n",
    "        #return loss\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6691669c",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "Now, we set up the training arguments for logging and evaluation every epoch. This shows us the evaluation metrics at the end of every epoch. This can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72d077f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 142\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 5\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 5\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 87\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='87' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [87/87 00:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score Samples Mean</th>\n",
       "      <th>F1 Score Macro Mean</th>\n",
       "      <th>Roc Auc Samples Mean</th>\n",
       "      <th>Roc Auc Macro Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.662200</td>\n",
       "      <td>0.635755</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.611905</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.611220</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.611905</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.586600</td>\n",
       "      <td>0.601642</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.611905</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 35\n",
      "  Batch size = 5\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35\n",
      "  Batch size = 5\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35\n",
      "  Batch size = 5\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set parameters around training\n",
    "training_args = TrainingArguments(\"test_trainer\", \n",
    "                                  logging_strategy='epoch', \n",
    "                                  evaluation_strategy='epoch',\n",
    "                                  num_train_epochs = 3,\n",
    "                                  learning_rate = 2e-5,\n",
    "                                  weight_decay = 1e-5,\n",
    "                                  #lr_scheduler_type = 'cosine',\n",
    "                                  #adam_beta1 = 0.8,\n",
    "                                  #adam_beta2 = 0.95,\n",
    "                                  #adam_epsilon = 1e-6,\n",
    "                                  per_device_train_batch_size=5,\n",
    "                                  per_device_eval_batch_size=5,\n",
    "                                  report_to='all'\n",
    "                                 )\n",
    "    \n",
    "trainer = MultilabelTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=processor,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "train_output = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c941ccba",
   "metadata": {},
   "source": [
    "# Evaluate Model\n",
    "If we want to evaluate the performance, we can use the evaluate method of trainer. This shows us all of our metrics from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c31949d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 142\n",
      "  Batch size = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5638657212257385,\n",
       " 'eval_f1_score_samples_mean': 0.5023474178403755,\n",
       " 'eval_f1_score_macro_mean': 0.17129629629629628,\n",
       " 'eval_roc_auc_samples_mean': 0.6625586854460095,\n",
       " 'eval_roc_auc_macro_mean': 0.5,\n",
       " 'eval_runtime': 8.9881,\n",
       " 'eval_samples_per_second': 15.799,\n",
       " 'eval_steps_per_second': 3.227,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fefc3a",
   "metadata": {},
   "source": [
    "The model is doing pretty rough, but hopefully it will improve with the use of more data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b501597",
   "metadata": {},
   "source": [
    "# Look at predictions\n",
    "Let's check out the probabilities themselves since we don't see a lot of movement in the evaluation metrics (we'll look at the training set here, though...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04daea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 142\n",
      "  Batch size = 5\n"
     ]
    }
   ],
   "source": [
    "#Get predictions\n",
    "train_preds = trainer.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b770e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5307, 0.4796, 0.2736, 0.3569],\n",
       "        [0.5287, 0.4785, 0.2781, 0.3590],\n",
       "        [0.5299, 0.4816, 0.2942, 0.3692],\n",
       "        [0.5289, 0.4796, 0.2668, 0.3518],\n",
       "        [0.5313, 0.4799, 0.2740, 0.3561],\n",
       "        [0.5285, 0.4762, 0.2768, 0.3573],\n",
       "        [0.5291, 0.4793, 0.2670, 0.3523],\n",
       "        [0.5301, 0.4803, 0.3096, 0.3806],\n",
       "        [0.5277, 0.4787, 0.2653, 0.3503],\n",
       "        [0.5303, 0.4784, 0.2682, 0.3523],\n",
       "        [0.5297, 0.4784, 0.2656, 0.3517],\n",
       "        [0.5314, 0.4789, 0.2714, 0.3534],\n",
       "        [0.5301, 0.4792, 0.2841, 0.3616],\n",
       "        [0.5316, 0.4775, 0.2820, 0.3631],\n",
       "        [0.5248, 0.4782, 0.2791, 0.3608],\n",
       "        [0.5304, 0.4770, 0.2943, 0.3713],\n",
       "        [0.5268, 0.4767, 0.2669, 0.3522],\n",
       "        [0.5258, 0.4799, 0.3210, 0.3883],\n",
       "        [0.5277, 0.4768, 0.2677, 0.3534],\n",
       "        [0.5258, 0.4774, 0.2724, 0.3560],\n",
       "        [0.5261, 0.4799, 0.3345, 0.3964],\n",
       "        [0.5291, 0.4813, 0.2860, 0.3652],\n",
       "        [0.5251, 0.4768, 0.2713, 0.3554],\n",
       "        [0.5300, 0.4793, 0.2690, 0.3520],\n",
       "        [0.5282, 0.4781, 0.2829, 0.3610],\n",
       "        [0.5306, 0.4774, 0.2661, 0.3508],\n",
       "        [0.5283, 0.4806, 0.2847, 0.3623],\n",
       "        [0.5301, 0.4800, 0.2721, 0.3536],\n",
       "        [0.5245, 0.4774, 0.2764, 0.3587],\n",
       "        [0.5253, 0.4771, 0.2706, 0.3545],\n",
       "        [0.5293, 0.4779, 0.2647, 0.3486],\n",
       "        [0.5268, 0.4778, 0.2667, 0.3506],\n",
       "        [0.5309, 0.4784, 0.2654, 0.3499],\n",
       "        [0.5260, 0.4772, 0.2705, 0.3550],\n",
       "        [0.5250, 0.4772, 0.2773, 0.3600],\n",
       "        [0.5274, 0.4806, 0.3007, 0.3700],\n",
       "        [0.5283, 0.4773, 0.2812, 0.3625],\n",
       "        [0.5280, 0.4792, 0.2643, 0.3518],\n",
       "        [0.5268, 0.4797, 0.3069, 0.3771],\n",
       "        [0.5257, 0.4774, 0.2704, 0.3546],\n",
       "        [0.5309, 0.4779, 0.2703, 0.3538],\n",
       "        [0.5243, 0.4767, 0.2772, 0.3592],\n",
       "        [0.5275, 0.4775, 0.2701, 0.3551],\n",
       "        [0.5297, 0.4777, 0.2773, 0.3590],\n",
       "        [0.5268, 0.4765, 0.2682, 0.3503],\n",
       "        [0.5267, 0.4773, 0.2682, 0.3527],\n",
       "        [0.5299, 0.4788, 0.2757, 0.3577],\n",
       "        [0.5307, 0.4776, 0.2772, 0.3574],\n",
       "        [0.5249, 0.4769, 0.2752, 0.3579],\n",
       "        [0.5290, 0.4784, 0.2692, 0.3547],\n",
       "        [0.5280, 0.4787, 0.2675, 0.3528],\n",
       "        [0.5283, 0.4780, 0.2690, 0.3528],\n",
       "        [0.5272, 0.4775, 0.2767, 0.3582],\n",
       "        [0.5238, 0.4777, 0.2787, 0.3602],\n",
       "        [0.5282, 0.4771, 0.2663, 0.3520],\n",
       "        [0.5294, 0.4784, 0.2658, 0.3519],\n",
       "        [0.5270, 0.4784, 0.2659, 0.3515],\n",
       "        [0.5322, 0.4794, 0.2706, 0.3526],\n",
       "        [0.5245, 0.4764, 0.2779, 0.3598],\n",
       "        [0.5266, 0.4774, 0.2718, 0.3558],\n",
       "        [0.5288, 0.4769, 0.2675, 0.3507],\n",
       "        [0.5318, 0.4762, 0.2896, 0.3677],\n",
       "        [0.5243, 0.4760, 0.2742, 0.3571],\n",
       "        [0.5257, 0.4775, 0.2756, 0.3573],\n",
       "        [0.5308, 0.4788, 0.2690, 0.3534],\n",
       "        [0.5261, 0.4784, 0.2776, 0.3604],\n",
       "        [0.5269, 0.4776, 0.2666, 0.3522],\n",
       "        [0.5303, 0.4780, 0.2736, 0.3560],\n",
       "        [0.5271, 0.4762, 0.2739, 0.3555],\n",
       "        [0.5255, 0.4781, 0.2965, 0.3731],\n",
       "        [0.5243, 0.4761, 0.2751, 0.3580],\n",
       "        [0.5256, 0.4752, 0.2706, 0.3546],\n",
       "        [0.5301, 0.4767, 0.2878, 0.3646],\n",
       "        [0.5300, 0.4780, 0.2628, 0.3489],\n",
       "        [0.5251, 0.4791, 0.3020, 0.3715],\n",
       "        [0.5287, 0.4784, 0.2667, 0.3495],\n",
       "        [0.5260, 0.4778, 0.2745, 0.3582],\n",
       "        [0.5266, 0.4766, 0.2670, 0.3522],\n",
       "        [0.5285, 0.4797, 0.2702, 0.3526],\n",
       "        [0.5244, 0.4764, 0.2765, 0.3586],\n",
       "        [0.5263, 0.4756, 0.2693, 0.3538],\n",
       "        [0.5314, 0.4779, 0.2654, 0.3493],\n",
       "        [0.5287, 0.4781, 0.2717, 0.3535],\n",
       "        [0.5282, 0.4780, 0.2702, 0.3529],\n",
       "        [0.5282, 0.4754, 0.2777, 0.3565],\n",
       "        [0.5305, 0.4759, 0.2761, 0.3572],\n",
       "        [0.5268, 0.4772, 0.2697, 0.3536],\n",
       "        [0.5314, 0.4787, 0.2705, 0.3518],\n",
       "        [0.5304, 0.4794, 0.2647, 0.3504],\n",
       "        [0.5284, 0.4785, 0.2985, 0.3737],\n",
       "        [0.5297, 0.4786, 0.2645, 0.3508],\n",
       "        [0.5278, 0.4799, 0.2954, 0.3712],\n",
       "        [0.5278, 0.4776, 0.2667, 0.3524],\n",
       "        [0.5251, 0.4818, 0.3100, 0.3789],\n",
       "        [0.5301, 0.4779, 0.2874, 0.3636],\n",
       "        [0.5283, 0.4765, 0.2656, 0.3508],\n",
       "        [0.5300, 0.4788, 0.2808, 0.3592],\n",
       "        [0.5257, 0.4761, 0.2722, 0.3561],\n",
       "        [0.5256, 0.4786, 0.2786, 0.3600],\n",
       "        [0.5358, 0.4780, 0.2888, 0.3653],\n",
       "        [0.5273, 0.4774, 0.2717, 0.3547],\n",
       "        [0.5271, 0.4770, 0.2672, 0.3517],\n",
       "        [0.5287, 0.4773, 0.2676, 0.3522],\n",
       "        [0.5261, 0.4767, 0.2705, 0.3542],\n",
       "        [0.5262, 0.4764, 0.2703, 0.3527],\n",
       "        [0.5289, 0.4785, 0.2650, 0.3520],\n",
       "        [0.5294, 0.4762, 0.2720, 0.3554],\n",
       "        [0.5318, 0.4764, 0.2720, 0.3538],\n",
       "        [0.5292, 0.4779, 0.3105, 0.3798],\n",
       "        [0.5336, 0.4809, 0.2752, 0.3563],\n",
       "        [0.5272, 0.4783, 0.2667, 0.3523],\n",
       "        [0.5273, 0.4776, 0.2668, 0.3511],\n",
       "        [0.5288, 0.4780, 0.2673, 0.3514],\n",
       "        [0.5297, 0.4802, 0.2686, 0.3528],\n",
       "        [0.5274, 0.4775, 0.2713, 0.3528],\n",
       "        [0.5316, 0.4788, 0.2695, 0.3514],\n",
       "        [0.5240, 0.4779, 0.2782, 0.3596],\n",
       "        [0.5281, 0.4789, 0.2686, 0.3505],\n",
       "        [0.5299, 0.4782, 0.2653, 0.3508],\n",
       "        [0.5280, 0.4775, 0.2668, 0.3513],\n",
       "        [0.5282, 0.4778, 0.2655, 0.3496],\n",
       "        [0.5292, 0.4789, 0.2701, 0.3518],\n",
       "        [0.5300, 0.4745, 0.2683, 0.3516],\n",
       "        [0.5289, 0.4771, 0.2657, 0.3513],\n",
       "        [0.5290, 0.4793, 0.2664, 0.3501],\n",
       "        [0.5312, 0.4794, 0.2784, 0.3575],\n",
       "        [0.5263, 0.4777, 0.2676, 0.3529],\n",
       "        [0.5289, 0.4785, 0.2650, 0.3510],\n",
       "        [0.5278, 0.4764, 0.2664, 0.3497],\n",
       "        [0.5310, 0.4748, 0.2736, 0.3542],\n",
       "        [0.5255, 0.4773, 0.2757, 0.3581],\n",
       "        [0.5290, 0.4783, 0.2622, 0.3500],\n",
       "        [0.5302, 0.4776, 0.2684, 0.3518],\n",
       "        [0.5261, 0.4765, 0.2672, 0.3543],\n",
       "        [0.5259, 0.4772, 0.2699, 0.3538],\n",
       "        [0.5333, 0.4752, 0.2925, 0.3683],\n",
       "        [0.5291, 0.4778, 0.2779, 0.3565],\n",
       "        [0.5291, 0.4782, 0.2690, 0.3535],\n",
       "        [0.5293, 0.4802, 0.2874, 0.3632],\n",
       "        [0.5273, 0.4758, 0.3091, 0.3779],\n",
       "        [0.5319, 0.4777, 0.2673, 0.3511],\n",
       "        [0.5301, 0.4763, 0.2682, 0.3508]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run sigmoid to get probabilities\n",
    "torch.sigmoid(torch.tensor(train_preds.predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07145309",
   "metadata": {},
   "source": [
    "This tells us a lot about what we saw during training. The probabilities themselves really aren't all that different in value across the different samples. A good sign is that they are different, but they will need to be differentiated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
